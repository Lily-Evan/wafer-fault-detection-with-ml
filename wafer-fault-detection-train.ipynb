{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12496070,"sourceType":"datasetVersion","datasetId":7886126}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Έξυπνη Ανίχνευση Σφαλμάτων (Fault Detection) σε MEMS με Machine Learnin","metadata":{}},{"cell_type":"markdown","source":"\nRepository files navigation\nREADME\nWafer Fault Detection\nAPP URL : - https://waferfaultdetection16.herokuapp.com/\n\nClick On - Train WaferFault Detection to Train the Model with the EXISTING Data Available\n\nClick On- Default File Predict to PREDICT the Model with the EXISTING Data Available\n\nClick On- Custom File Predict to PREDICT the Model While Providing Proper Data\n\nProblem Statement:\nWafer (In electronics), also called a slice or substrate, is a thin slice of semiconductor,\nsuch as a crystalline silicon (c-Si), used for fabricationof integrated circuits and in photovoltaics,\nto manufacture solar cells.\n\nThe inputs of various sensors for different wafers have been provided.\nThe goal is to build a machine learning model which predicts whether a wafer needs to be replaced or not\n(i.e whether it is working or not) nased on the inputs from various sensors.\nThere are two classes: +1 and -1.\n+1: Means that the wafer is in a working condition and it doesn't need to be replaced.\n-1: Means that the wafer is faulty and it needa to be replaced.\nData Description\nThe client will send data in multiple sets of files in batches at a given location.\nData will contain Wafer names and 590 columns of different sensor values for each wafer.\nThe last column will have the \"Good/Bad\" value for each wafer.\n\nApart from training files, we laso require a \"schema\" file from the client, which contain all the\nrelevant information about the training files such as:\n\nName of the files, Length of Date value in FileName, Length of Time value in FileName, NUmber of Columnns, \nName of Columns, and their dataype.\nData Validation\nIn This step, we perform different sets of validation on the given set of training files.\n\nName Validation: We validate the name of the files based on the given name in the schema file. We have \ncreated a regex patterg as per the name given in the schema fileto use for validation. After validating \nthe pattern in the name, we check for the length of the date in the file name as well as the length of time \nin the file name. If all the values are as per requirements, we move such files to \"Good_Data_Folder\" else\nwe move such files to \"Bad_Data_Folder.\"\n\nNumber of Columns: We validate the number of columns present in the files, and if it doesn't match with the\nvalue given in the schema file, then the file id moves to \"Bad_Data_Folder.\"\n\nName of Columns: The name of the columns is validated and should be the same as given in the schema file. \nIf not, then the file is moved to \"Bad_Data_Folder\".\n\nThe datatype of columns: The datatype of columns is given in the schema file. This is validated when we insert\nthe files into Database. If the datatype is wrong, then the file is moved to \"Bad_Data_Folder.\"\n\nNull values in columns: If any of the columns in a file have all the values as NULL or missing, we discard such\na file and move it to \"Bad_Data_Folder\".\nData Insertion in Database\n Database Creation and Connection: Create a database with the given name passed. If the database is already created,\n open the connection to the database.\n \n Table creation in the database: Table with name - \"Good_Data\", is created in the database for inserting the files \n in the \"Good_Data_Folder\" based on given column names and datatype in the schema file. If the table is already\n present, then the new table is not created and new files are inserted in the already present table as we want \n training to be done on new as well as old training files.\n \n Insertion of file in the table: All the files in the \"Good_Data_Folder\" are inserted in the above-created table. If\n any file has invalid data type in any of the columns, the file is not loaded in the table and is moved to \n \"Bad_Data_Folder\".\nModel Training\n Data Export from Db: The data in a stored database is exported as a CSV file to be used for model training.\n \n Data Preprocessing: \n    Check for null values in the columns. If present, impute the null values using the KNN imputer.\n    \n    Check if any column has zero standard deviation, remove such columns as they don't give any information during \n    model training.\n    \n Clustering: KMeans algorithm is used to create clusters in the preprocessed data. The optimum number of clusters \n is selected\nCreate a file \"Dockerfile\" with below content\nFROM python:3.7\nCOPY . /app\nWORKDIR /app\nRUN pip install -r requirements.txt\nENTRYPOINT [ \"python\" ]\nCMD [ \"main.py\" ]\nCreate a \"Procfile\" with following content\nweb: gunicorn main:app\ncreate a file \".circleci\\config.yml\" with following content\nversion: 2.1\norbs:\n  heroku: circleci/heroku@1.0.1\njobs:\n  build-and-test:\n    executor: heroku/default\n    docker:\n      - image: circleci/python:3.6.2-stretch-browsers\n        auth:\n          username: mydockerhub-user\n          password: $DOCKERHUB_PASSWORD  # context / project UI env-var reference\n    steps:\n      - checkout\n      - restore_cache:\n          key: deps1-{{ .Branch }}-{{ checksum \"requirements.txt\" }}\n      - run:\n          name: Install Python deps in a venv\n          command: |\n            echo 'export TAG=0.1.${CIRCLE_BUILD_NUM}' >> $BASH_ENV\n            echo 'export IMAGE_NAME=python-circleci-docker' >> $BASH_ENV\n            python3 -m venv venv\n            . venv/bin/activate\n            pip install --upgrade pip\n            pip install -r requirements.txt\n      - save_cache:\n          key: deps1-{{ .Branch }}-{{ checksum \"requirements.txt\" }}\n          paths:\n            - \"venv\"\n      - run:\n          command: |\n            . venv/bin/activate\n            python -m pytest -v tests/test_script.py\n      - store_artifacts:\n          path: test-reports/\n          destination: tr1\n      - store_test_results:\n          path: test-reports/\n      - setup_remote_docker:\n          version: 19.03.13\n      - run:\n          name: Build and push Docker image\n          command: |\n            docker build -t $DOCKERHUB_USER/$IMAGE_NAME:$TAG .\n            docker login -u $DOCKERHUB_USER -p $DOCKER_HUB_PASSWORD_USER docker.io\n            docker push $DOCKERHUB_USER/$IMAGE_NAME:$TAG\n  deploy:\n    executor: heroku/default\n    steps:\n      - checkout\n      - run:\n          name: Storing previous commit\n          command: |\n            git rev-parse HEAD > ./commit.txt\n      - heroku/install\n      - setup_remote_docker:\n          version: 18.06.0-ce\n      - run:\n          name: Pushing to heroku registry\n          command: |\n            heroku container:login\n            #heroku ps:scale web=1 -a $HEROKU_APP_NAME\n            heroku container:push web -a $HEROKU_APP_NAME\n            heroku container:release web -a $HEROKU_APP_NAME\n\nworkflows:\n  build-test-deploy:\n    jobs:\n      - build-and-test\n      - deploy:\n          requires:\n            - build-and-test\n          filters:\n            branches:\n              only:\n                - main\nto create requirements.txt\npip freeze>requirements.txt\ninitialize git repo\ngit init\ngit add .\ngit commit -m \"first commit\"\ngit branch -M main\ngit remote add origin <github_url>\ngit push -u origin main\ncreate a account at circle ci\nCircle CI\n\nsetup your project\nSetup project\n\nSelect project setting in CircleCI and below environment variable\nDOCKERHUB_USER\nDOCKER_HUB_PASSWORD_USER\nHEROKU_API_KEY\nHEROKU_APP_NAME\nHEROKU_EMAIL_ADDRESS\nDOCKER_IMAGE_NAME=wafercircle3270303\nto update the modification\ngit add .\ngit commit -m \"proper message\"\ngit push \n#docker login -u $DOCKERHUB_USER -p $DOCKER_HUB_PASSWORD_USER docker.io\nAbout\nA Machine Learning model which predicts whether a wafer needs to be replaced or not (i.e whether it is working (+1 ) or not( -1)) based on the inputs from various sensors.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-17T08:41:28.532547Z","iopub.execute_input":"2025-07-17T08:41:28.532868Z","iopub.status.idle":"2025-07-17T08:41:31.255168Z","shell.execute_reply.started":"2025-07-17T08:41:28.532836Z","shell.execute_reply":"2025-07-17T08:41:31.254163Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/wafer-fault-detection/wafer_07012020_041011.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score,roc_auc_score\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nfrom sklearn.impute import KNNImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,roc_auc_score\nimport pickle","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T08:41:47.721360Z","iopub.execute_input":"2025-07-17T08:41:47.721688Z","iopub.status.idle":"2025-07-17T08:41:49.556011Z","shell.execute_reply.started":"2025-07-17T08:41:47.721665Z","shell.execute_reply":"2025-07-17T08:41:49.555005Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\n\ndata = pd.read_csv('/kaggle/input/wafer-fault-detection/wafer_07012020_041011.csv')\ndata.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T08:44:21.643789Z","iopub.execute_input":"2025-07-17T08:44:21.644152Z","iopub.status.idle":"2025-07-17T08:44:21.748687Z","shell.execute_reply.started":"2025-07-17T08:44:21.644127Z","shell.execute_reply":"2025-07-17T08:44:21.747346Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"  Unnamed: 0  Sensor-1  Sensor-2   Sensor-3   Sensor-4  Sensor-5  Sensor-6  \\\n0  Wafer-501   3076.81   2158.75  2208.2334  1517.0152    1.0980       100   \n1  Wafer-502   2951.62   2511.92  2253.5111  1397.5060    0.9660       100   \n2  Wafer-503   2930.42   2505.17  2235.0556  1302.6607    1.6347       100   \n3  Wafer-504   2997.28   2357.99  2141.0667  1236.5212    0.9698       100   \n4  Wafer-505   3025.10   2475.18  2235.0556  1302.6607    1.6347       100   \n\n   Sensor-7  Sensor-8  Sensor-9  ...  Sensor-582  Sensor-583  Sensor-584  \\\n0  110.1900    0.1247    1.4357  ...     64.2405      0.5016      0.0152   \n1  109.7611    0.1210    1.5527  ...      0.0000      0.4953      0.0105   \n2  109.9856    0.1230    1.4588  ...         NaN      0.4958      0.0111   \n3   98.3344    0.1238    1.5973  ...         NaN      0.4962      0.0086   \n4  109.9856    0.1230    1.5525  ...         NaN      0.4983      0.0159   \n\n   Sensor-585  Sensor-586  Sensor-587  Sensor-588  Sensor-589  Sensor-590  \\\n0      0.0040      3.0319      0.0465      0.0299      0.0090     64.2405   \n1      0.0037      2.1266     -0.0012      0.0252      0.0081      0.0000   \n2      0.0033      2.2296     -0.0012      0.0252      0.0081      0.0000   \n3      0.0024      1.7297     -0.0012      0.0252      0.0081      0.0000   \n4      0.0041      3.1927     -0.0012      0.0252      0.0081      0.0000   \n\n   Good/Bad  \n0        -1  \n1        -1  \n2        -1  \n3        -1  \n4        -1  \n\n[5 rows x 592 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Sensor-1</th>\n      <th>Sensor-2</th>\n      <th>Sensor-3</th>\n      <th>Sensor-4</th>\n      <th>Sensor-5</th>\n      <th>Sensor-6</th>\n      <th>Sensor-7</th>\n      <th>Sensor-8</th>\n      <th>Sensor-9</th>\n      <th>...</th>\n      <th>Sensor-582</th>\n      <th>Sensor-583</th>\n      <th>Sensor-584</th>\n      <th>Sensor-585</th>\n      <th>Sensor-586</th>\n      <th>Sensor-587</th>\n      <th>Sensor-588</th>\n      <th>Sensor-589</th>\n      <th>Sensor-590</th>\n      <th>Good/Bad</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Wafer-501</td>\n      <td>3076.81</td>\n      <td>2158.75</td>\n      <td>2208.2334</td>\n      <td>1517.0152</td>\n      <td>1.0980</td>\n      <td>100</td>\n      <td>110.1900</td>\n      <td>0.1247</td>\n      <td>1.4357</td>\n      <td>...</td>\n      <td>64.2405</td>\n      <td>0.5016</td>\n      <td>0.0152</td>\n      <td>0.0040</td>\n      <td>3.0319</td>\n      <td>0.0465</td>\n      <td>0.0299</td>\n      <td>0.0090</td>\n      <td>64.2405</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Wafer-502</td>\n      <td>2951.62</td>\n      <td>2511.92</td>\n      <td>2253.5111</td>\n      <td>1397.5060</td>\n      <td>0.9660</td>\n      <td>100</td>\n      <td>109.7611</td>\n      <td>0.1210</td>\n      <td>1.5527</td>\n      <td>...</td>\n      <td>0.0000</td>\n      <td>0.4953</td>\n      <td>0.0105</td>\n      <td>0.0037</td>\n      <td>2.1266</td>\n      <td>-0.0012</td>\n      <td>0.0252</td>\n      <td>0.0081</td>\n      <td>0.0000</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Wafer-503</td>\n      <td>2930.42</td>\n      <td>2505.17</td>\n      <td>2235.0556</td>\n      <td>1302.6607</td>\n      <td>1.6347</td>\n      <td>100</td>\n      <td>109.9856</td>\n      <td>0.1230</td>\n      <td>1.4588</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.4958</td>\n      <td>0.0111</td>\n      <td>0.0033</td>\n      <td>2.2296</td>\n      <td>-0.0012</td>\n      <td>0.0252</td>\n      <td>0.0081</td>\n      <td>0.0000</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Wafer-504</td>\n      <td>2997.28</td>\n      <td>2357.99</td>\n      <td>2141.0667</td>\n      <td>1236.5212</td>\n      <td>0.9698</td>\n      <td>100</td>\n      <td>98.3344</td>\n      <td>0.1238</td>\n      <td>1.5973</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.4962</td>\n      <td>0.0086</td>\n      <td>0.0024</td>\n      <td>1.7297</td>\n      <td>-0.0012</td>\n      <td>0.0252</td>\n      <td>0.0081</td>\n      <td>0.0000</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wafer-505</td>\n      <td>3025.10</td>\n      <td>2475.18</td>\n      <td>2235.0556</td>\n      <td>1302.6607</td>\n      <td>1.6347</td>\n      <td>100</td>\n      <td>109.9856</td>\n      <td>0.1230</td>\n      <td>1.5525</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.4983</td>\n      <td>0.0159</td>\n      <td>0.0041</td>\n      <td>3.1927</td>\n      <td>-0.0012</td>\n      <td>0.0252</td>\n      <td>0.0081</td>\n      <td>0.0000</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 592 columns</p>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"data.rename(columns={\"Unnamed: 0\":\"Wafer\"},inplace=True)\ndata.rename(columns={\"Good/Bad\":\"Output\"},inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T08:44:32.265870Z","iopub.execute_input":"2025-07-17T08:44:32.266210Z","iopub.status.idle":"2025-07-17T08:44:32.276035Z","shell.execute_reply.started":"2025-07-17T08:44:32.266187Z","shell.execute_reply":"2025-07-17T08:44:32.275016Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"data.iloc[0:1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T08:44:40.041352Z","iopub.execute_input":"2025-07-17T08:44:40.042143Z","iopub.status.idle":"2025-07-17T08:44:40.190627Z","shell.execute_reply.started":"2025-07-17T08:44:40.042096Z","shell.execute_reply":"2025-07-17T08:44:40.189466Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"       Wafer  Sensor-1  Sensor-2   Sensor-3   Sensor-4  Sensor-5  Sensor-6  \\\n0  Wafer-501   3076.81   2158.75  2208.2334  1517.0152     1.098       100   \n\n   Sensor-7  Sensor-8  Sensor-9  ...  Sensor-582  Sensor-583  Sensor-584  \\\n0    110.19    0.1247    1.4357  ...     64.2405      0.5016      0.0152   \n\n   Sensor-585  Sensor-586  Sensor-587  Sensor-588  Sensor-589  Sensor-590  \\\n0       0.004      3.0319      0.0465      0.0299       0.009     64.2405   \n\n   Output  \n0      -1  \n\n[1 rows x 592 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Wafer</th>\n      <th>Sensor-1</th>\n      <th>Sensor-2</th>\n      <th>Sensor-3</th>\n      <th>Sensor-4</th>\n      <th>Sensor-5</th>\n      <th>Sensor-6</th>\n      <th>Sensor-7</th>\n      <th>Sensor-8</th>\n      <th>Sensor-9</th>\n      <th>...</th>\n      <th>Sensor-582</th>\n      <th>Sensor-583</th>\n      <th>Sensor-584</th>\n      <th>Sensor-585</th>\n      <th>Sensor-586</th>\n      <th>Sensor-587</th>\n      <th>Sensor-588</th>\n      <th>Sensor-589</th>\n      <th>Sensor-590</th>\n      <th>Output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Wafer-501</td>\n      <td>3076.81</td>\n      <td>2158.75</td>\n      <td>2208.2334</td>\n      <td>1517.0152</td>\n      <td>1.098</td>\n      <td>100</td>\n      <td>110.19</td>\n      <td>0.1247</td>\n      <td>1.4357</td>\n      <td>...</td>\n      <td>64.2405</td>\n      <td>0.5016</td>\n      <td>0.0152</td>\n      <td>0.004</td>\n      <td>3.0319</td>\n      <td>0.0465</td>\n      <td>0.0299</td>\n      <td>0.009</td>\n      <td>64.2405</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 592 columns</p>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"data.isna().sum(True) # check for the count of null values per column","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T08:44:52.146426Z","iopub.execute_input":"2025-07-17T08:44:52.146809Z","iopub.status.idle":"2025-07-17T08:44:52.158626Z","shell.execute_reply.started":"2025-07-17T08:44:52.146787Z","shell.execute_reply":"2025-07-17T08:44:52.157452Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"0     36\n1     32\n2     36\n3     48\n4     48\n      ..\n95    28\n96    36\n97    36\n98    28\n99    32\nLength: 100, dtype: int64"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"data.fillna(\"NaN\",inplace=True) #filling with null values for now\ndata.isnull().sum(True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T08:45:12.874109Z","iopub.execute_input":"2025-07-17T08:45:12.875050Z","iopub.status.idle":"2025-07-17T08:45:12.910798Z","shell.execute_reply.started":"2025-07-17T08:45:12.875019Z","shell.execute_reply":"2025-07-17T08:45:12.909771Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/3464390532.py:1: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'NaN' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n  data.fillna(\"NaN\",inplace=True) #filling with null values for now\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"0     0\n1     0\n2     0\n3     0\n4     0\n     ..\n95    0\n96    0\n97    0\n98    0\n99    0\nLength: 100, dtype: int64"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"data1=data.drop([\"Wafer\"],axis=1) # remove the unnamed column as it doesn't contribute to prediction.\ndata1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T08:45:24.578974Z","iopub.execute_input":"2025-07-17T08:45:24.579329Z","iopub.status.idle":"2025-07-17T08:45:24.632295Z","shell.execute_reply.started":"2025-07-17T08:45:24.579306Z","shell.execute_reply":"2025-07-17T08:45:24.631153Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"   Sensor-1 Sensor-2   Sensor-3   Sensor-4  Sensor-5  Sensor-6  Sensor-7  \\\n0   3076.81  2158.75  2208.2334  1517.0152    1.0980       100  110.1900   \n1   2951.62  2511.92  2253.5111  1397.5060    0.9660       100  109.7611   \n2   2930.42  2505.17  2235.0556  1302.6607    1.6347       100  109.9856   \n3   2997.28  2357.99  2141.0667  1236.5212    0.9698       100   98.3344   \n4    3025.1  2475.18  2235.0556  1302.6607    1.6347       100  109.9856   \n..      ...      ...        ...        ...       ...       ...       ...   \n95  2996.89   2492.4  2217.8667  1275.0917    1.5487       100  105.2933   \n96  2990.85  2485.99  2167.9444   861.8041    1.4140       100  106.6033   \n97  3059.43  2473.55  2214.9333  1663.7024    1.0203       100  100.4456   \n98  3024.54  2420.25  2167.9444   861.8041    1.4140       100  106.6033   \n99  3069.44   2459.5  2183.5000  1099.0027    1.3593       100  104.4156   \n\n    Sensor-8  Sensor-9  Sensor-10  ...  Sensor-582  Sensor-583  Sensor-584  \\\n0     0.1247    1.4357     0.0089  ...     64.2405      0.5016      0.0152   \n1     0.1210    1.5527     0.0119  ...         0.0      0.4953      0.0105   \n2     0.1230    1.4588    -0.0143  ...         NaN      0.4958      0.0111   \n3     0.1238    1.5973    -0.0534  ...         NaN      0.4962      0.0086   \n4     0.1230    1.5525    -0.0078  ...         NaN      0.4983      0.0159   \n..       ...       ...        ...  ...         ...         ...         ...   \n95    0.1230    1.5455    -0.0140  ...         NaN      0.5071      0.0123   \n96    0.1243    1.4647    -0.0212  ...         NaN      0.5015      0.0130   \n97    0.1247    1.4262    -0.0209  ...    108.6076      0.4973      0.0073   \n98    0.1243    1.4849    -0.0072  ...         NaN      0.5006      0.0068   \n99    0.1220    1.5549    -0.0130  ...         NaN      0.5014      0.0090   \n\n    Sensor-585  Sensor-586  Sensor-587  Sensor-588  Sensor-589  Sensor-590  \\\n0       0.0040      3.0319      0.0465      0.0299      0.0090     64.2405   \n1       0.0037      2.1266     -0.0012      0.0252      0.0081      0.0000   \n2       0.0033      2.2296     -0.0012      0.0252      0.0081      0.0000   \n3       0.0024      1.7297     -0.0012      0.0252      0.0081      0.0000   \n4       0.0041      3.1927     -0.0012      0.0252      0.0081      0.0000   \n..         ...         ...         ...         ...         ...         ...   \n95      0.0038      2.4294      0.0227      0.0149      0.0052     65.4831   \n96      0.0042      2.5884      0.0227      0.0149      0.0052     65.4831   \n97      0.0017      1.4716      0.0300      0.0326      0.0114    108.6076   \n98      0.0018      1.3667      0.0300      0.0326      0.0114    108.6076   \n99      0.0026      1.8039      0.0300      0.0326      0.0114    108.6076   \n\n    Output  \n0       -1  \n1       -1  \n2       -1  \n3       -1  \n4       -1  \n..     ...  \n95      -1  \n96      -1  \n97      -1  \n98      -1  \n99      -1  \n\n[100 rows x 591 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sensor-1</th>\n      <th>Sensor-2</th>\n      <th>Sensor-3</th>\n      <th>Sensor-4</th>\n      <th>Sensor-5</th>\n      <th>Sensor-6</th>\n      <th>Sensor-7</th>\n      <th>Sensor-8</th>\n      <th>Sensor-9</th>\n      <th>Sensor-10</th>\n      <th>...</th>\n      <th>Sensor-582</th>\n      <th>Sensor-583</th>\n      <th>Sensor-584</th>\n      <th>Sensor-585</th>\n      <th>Sensor-586</th>\n      <th>Sensor-587</th>\n      <th>Sensor-588</th>\n      <th>Sensor-589</th>\n      <th>Sensor-590</th>\n      <th>Output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3076.81</td>\n      <td>2158.75</td>\n      <td>2208.2334</td>\n      <td>1517.0152</td>\n      <td>1.0980</td>\n      <td>100</td>\n      <td>110.1900</td>\n      <td>0.1247</td>\n      <td>1.4357</td>\n      <td>0.0089</td>\n      <td>...</td>\n      <td>64.2405</td>\n      <td>0.5016</td>\n      <td>0.0152</td>\n      <td>0.0040</td>\n      <td>3.0319</td>\n      <td>0.0465</td>\n      <td>0.0299</td>\n      <td>0.0090</td>\n      <td>64.2405</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2951.62</td>\n      <td>2511.92</td>\n      <td>2253.5111</td>\n      <td>1397.5060</td>\n      <td>0.9660</td>\n      <td>100</td>\n      <td>109.7611</td>\n      <td>0.1210</td>\n      <td>1.5527</td>\n      <td>0.0119</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.4953</td>\n      <td>0.0105</td>\n      <td>0.0037</td>\n      <td>2.1266</td>\n      <td>-0.0012</td>\n      <td>0.0252</td>\n      <td>0.0081</td>\n      <td>0.0000</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2930.42</td>\n      <td>2505.17</td>\n      <td>2235.0556</td>\n      <td>1302.6607</td>\n      <td>1.6347</td>\n      <td>100</td>\n      <td>109.9856</td>\n      <td>0.1230</td>\n      <td>1.4588</td>\n      <td>-0.0143</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.4958</td>\n      <td>0.0111</td>\n      <td>0.0033</td>\n      <td>2.2296</td>\n      <td>-0.0012</td>\n      <td>0.0252</td>\n      <td>0.0081</td>\n      <td>0.0000</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2997.28</td>\n      <td>2357.99</td>\n      <td>2141.0667</td>\n      <td>1236.5212</td>\n      <td>0.9698</td>\n      <td>100</td>\n      <td>98.3344</td>\n      <td>0.1238</td>\n      <td>1.5973</td>\n      <td>-0.0534</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.4962</td>\n      <td>0.0086</td>\n      <td>0.0024</td>\n      <td>1.7297</td>\n      <td>-0.0012</td>\n      <td>0.0252</td>\n      <td>0.0081</td>\n      <td>0.0000</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3025.1</td>\n      <td>2475.18</td>\n      <td>2235.0556</td>\n      <td>1302.6607</td>\n      <td>1.6347</td>\n      <td>100</td>\n      <td>109.9856</td>\n      <td>0.1230</td>\n      <td>1.5525</td>\n      <td>-0.0078</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.4983</td>\n      <td>0.0159</td>\n      <td>0.0041</td>\n      <td>3.1927</td>\n      <td>-0.0012</td>\n      <td>0.0252</td>\n      <td>0.0081</td>\n      <td>0.0000</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>2996.89</td>\n      <td>2492.4</td>\n      <td>2217.8667</td>\n      <td>1275.0917</td>\n      <td>1.5487</td>\n      <td>100</td>\n      <td>105.2933</td>\n      <td>0.1230</td>\n      <td>1.5455</td>\n      <td>-0.0140</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.5071</td>\n      <td>0.0123</td>\n      <td>0.0038</td>\n      <td>2.4294</td>\n      <td>0.0227</td>\n      <td>0.0149</td>\n      <td>0.0052</td>\n      <td>65.4831</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>2990.85</td>\n      <td>2485.99</td>\n      <td>2167.9444</td>\n      <td>861.8041</td>\n      <td>1.4140</td>\n      <td>100</td>\n      <td>106.6033</td>\n      <td>0.1243</td>\n      <td>1.4647</td>\n      <td>-0.0212</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.5015</td>\n      <td>0.0130</td>\n      <td>0.0042</td>\n      <td>2.5884</td>\n      <td>0.0227</td>\n      <td>0.0149</td>\n      <td>0.0052</td>\n      <td>65.4831</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>3059.43</td>\n      <td>2473.55</td>\n      <td>2214.9333</td>\n      <td>1663.7024</td>\n      <td>1.0203</td>\n      <td>100</td>\n      <td>100.4456</td>\n      <td>0.1247</td>\n      <td>1.4262</td>\n      <td>-0.0209</td>\n      <td>...</td>\n      <td>108.6076</td>\n      <td>0.4973</td>\n      <td>0.0073</td>\n      <td>0.0017</td>\n      <td>1.4716</td>\n      <td>0.0300</td>\n      <td>0.0326</td>\n      <td>0.0114</td>\n      <td>108.6076</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>3024.54</td>\n      <td>2420.25</td>\n      <td>2167.9444</td>\n      <td>861.8041</td>\n      <td>1.4140</td>\n      <td>100</td>\n      <td>106.6033</td>\n      <td>0.1243</td>\n      <td>1.4849</td>\n      <td>-0.0072</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.5006</td>\n      <td>0.0068</td>\n      <td>0.0018</td>\n      <td>1.3667</td>\n      <td>0.0300</td>\n      <td>0.0326</td>\n      <td>0.0114</td>\n      <td>108.6076</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>3069.44</td>\n      <td>2459.5</td>\n      <td>2183.5000</td>\n      <td>1099.0027</td>\n      <td>1.3593</td>\n      <td>100</td>\n      <td>104.4156</td>\n      <td>0.1220</td>\n      <td>1.5549</td>\n      <td>-0.0130</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.5014</td>\n      <td>0.0090</td>\n      <td>0.0026</td>\n      <td>1.8039</td>\n      <td>0.0300</td>\n      <td>0.0326</td>\n      <td>0.0114</td>\n      <td>108.6076</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 591 columns</p>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"x=data1.drop([\"Output\"],axis=1) # create separate features and labels\nx.head(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T08:45:35.123293Z","iopub.execute_input":"2025-07-17T08:45:35.123935Z","iopub.status.idle":"2025-07-17T08:45:35.168019Z","shell.execute_reply.started":"2025-07-17T08:45:35.123898Z","shell.execute_reply":"2025-07-17T08:45:35.167021Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"  Sensor-1 Sensor-2   Sensor-3   Sensor-4  Sensor-5  Sensor-6  Sensor-7  \\\n0  3076.81  2158.75  2208.2334  1517.0152     1.098       100  110.1900   \n1  2951.62  2511.92  2253.5111  1397.5060     0.966       100  109.7611   \n\n   Sensor-8  Sensor-9  Sensor-10  ...  Sensor-581  Sensor-582  Sensor-583  \\\n0    0.1247    1.4357     0.0089  ...       0.009     64.2405      0.5016   \n1    0.1210    1.5527     0.0119  ...      0.0081         0.0      0.4953   \n\n   Sensor-584  Sensor-585  Sensor-586  Sensor-587  Sensor-588  Sensor-589  \\\n0      0.0152      0.0040      3.0319      0.0465      0.0299      0.0090   \n1      0.0105      0.0037      2.1266     -0.0012      0.0252      0.0081   \n\n   Sensor-590  \n0     64.2405  \n1      0.0000  \n\n[2 rows x 590 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sensor-1</th>\n      <th>Sensor-2</th>\n      <th>Sensor-3</th>\n      <th>Sensor-4</th>\n      <th>Sensor-5</th>\n      <th>Sensor-6</th>\n      <th>Sensor-7</th>\n      <th>Sensor-8</th>\n      <th>Sensor-9</th>\n      <th>Sensor-10</th>\n      <th>...</th>\n      <th>Sensor-581</th>\n      <th>Sensor-582</th>\n      <th>Sensor-583</th>\n      <th>Sensor-584</th>\n      <th>Sensor-585</th>\n      <th>Sensor-586</th>\n      <th>Sensor-587</th>\n      <th>Sensor-588</th>\n      <th>Sensor-589</th>\n      <th>Sensor-590</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3076.81</td>\n      <td>2158.75</td>\n      <td>2208.2334</td>\n      <td>1517.0152</td>\n      <td>1.098</td>\n      <td>100</td>\n      <td>110.1900</td>\n      <td>0.1247</td>\n      <td>1.4357</td>\n      <td>0.0089</td>\n      <td>...</td>\n      <td>0.009</td>\n      <td>64.2405</td>\n      <td>0.5016</td>\n      <td>0.0152</td>\n      <td>0.0040</td>\n      <td>3.0319</td>\n      <td>0.0465</td>\n      <td>0.0299</td>\n      <td>0.0090</td>\n      <td>64.2405</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2951.62</td>\n      <td>2511.92</td>\n      <td>2253.5111</td>\n      <td>1397.5060</td>\n      <td>0.966</td>\n      <td>100</td>\n      <td>109.7611</td>\n      <td>0.1210</td>\n      <td>1.5527</td>\n      <td>0.0119</td>\n      <td>...</td>\n      <td>0.0081</td>\n      <td>0.0</td>\n      <td>0.4953</td>\n      <td>0.0105</td>\n      <td>0.0037</td>\n      <td>2.1266</td>\n      <td>-0.0012</td>\n      <td>0.0252</td>\n      <td>0.0081</td>\n      <td>0.0000</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 590 columns</p>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"y=data1[\"Output\"]\ny.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T08:45:44.930319Z","iopub.execute_input":"2025-07-17T08:45:44.931428Z","iopub.status.idle":"2025-07-17T08:45:44.938574Z","shell.execute_reply.started":"2025-07-17T08:45:44.931394Z","shell.execute_reply":"2025-07-17T08:45:44.937512Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"0   -1\n1   -1\n2   -1\n3   -1\n4   -1\nName: Output, dtype: int64"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"data1.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T08:46:06.348068Z","iopub.execute_input":"2025-07-17T08:46:06.348560Z","iopub.status.idle":"2025-07-17T08:46:06.376877Z","shell.execute_reply.started":"2025-07-17T08:46:06.348529Z","shell.execute_reply":"2025-07-17T08:46:06.375641Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Sensor-1      0\nSensor-2      0\nSensor-3      0\nSensor-4      0\nSensor-5      0\n             ..\nSensor-587    0\nSensor-588    0\nSensor-589    0\nSensor-590    0\nOutput        0\nLength: 591, dtype: int64"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"imputer=KNNImputer(n_neighbors=3, weights='uniform',missing_values=np.nan)\nnew_data=imputer.fit_transform(x)\nx=pd.DataFrame(new_data)\nx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T08:46:16.763345Z","iopub.execute_input":"2025-07-17T08:46:16.763673Z","iopub.status.idle":"2025-07-17T08:46:16.919733Z","shell.execute_reply.started":"2025-07-17T08:46:16.763652Z","shell.execute_reply":"2025-07-17T08:46:16.918656Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"        0        1          2          3       4      5         6       7    \\\n0   3076.81  2158.75  2208.2334  1517.0152  1.0980  100.0  110.1900  0.1247   \n1   2951.62  2511.92  2253.5111  1397.5060  0.9660  100.0  109.7611  0.1210   \n2   2930.42  2505.17  2235.0556  1302.6607  1.6347  100.0  109.9856  0.1230   \n3   2997.28  2357.99  2141.0667  1236.5212  0.9698  100.0   98.3344  0.1238   \n4   3025.10  2475.18  2235.0556  1302.6607  1.6347  100.0  109.9856  0.1230   \n..      ...      ...        ...        ...     ...    ...       ...     ...   \n95  2996.89  2492.40  2217.8667  1275.0917  1.5487  100.0  105.2933  0.1230   \n96  2990.85  2485.99  2167.9444   861.8041  1.4140  100.0  106.6033  0.1243   \n97  3059.43  2473.55  2214.9333  1663.7024  1.0203  100.0  100.4456  0.1247   \n98  3024.54  2420.25  2167.9444   861.8041  1.4140  100.0  106.6033  0.1243   \n99  3069.44  2459.50  2183.5000  1099.0027  1.3593  100.0  104.4156  0.1220   \n\n       8       9    ...       564         565     566     567     568     569  \\\n0   1.4357  0.0089  ...  0.009000   64.240500  0.5016  0.0152  0.0040  3.0319   \n1   1.5527  0.0119  ...  0.008100    0.000000  0.4953  0.0105  0.0037  2.1266   \n2   1.4588 -0.0143  ...  0.004033   73.010633  0.4958  0.0111  0.0033  2.2296   \n3   1.5973 -0.0534  ...  0.005067   51.803633  0.4962  0.0086  0.0024  1.7297   \n4   1.5525 -0.0078  ...  0.005567   50.728767  0.4983  0.0159  0.0041  3.1927   \n..     ...     ...  ...       ...         ...     ...     ...     ...     ...   \n95  1.5455 -0.0140  ...  0.004300   35.549600  0.5071  0.0123  0.0038  2.4294   \n96  1.4647 -0.0212  ...  0.006167   52.293200  0.5015  0.0130  0.0042  2.5884   \n97  1.4262 -0.0209  ...  0.011400  108.607600  0.4973  0.0073  0.0017  1.4716   \n98  1.4849 -0.0072  ...  0.006167   52.293200  0.5006  0.0068  0.0018  1.3667   \n99  1.5549 -0.0130  ...  0.003933   54.506233  0.5014  0.0090  0.0026  1.8039   \n\n       570     571     572       573  \n0   0.0465  0.0299  0.0090   64.2405  \n1  -0.0012  0.0252  0.0081    0.0000  \n2  -0.0012  0.0252  0.0081    0.0000  \n3  -0.0012  0.0252  0.0081    0.0000  \n4  -0.0012  0.0252  0.0081    0.0000  \n..     ...     ...     ...       ...  \n95  0.0227  0.0149  0.0052   65.4831  \n96  0.0227  0.0149  0.0052   65.4831  \n97  0.0300  0.0326  0.0114  108.6076  \n98  0.0300  0.0326  0.0114  108.6076  \n99  0.0300  0.0326  0.0114  108.6076  \n\n[100 rows x 574 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>564</th>\n      <th>565</th>\n      <th>566</th>\n      <th>567</th>\n      <th>568</th>\n      <th>569</th>\n      <th>570</th>\n      <th>571</th>\n      <th>572</th>\n      <th>573</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3076.81</td>\n      <td>2158.75</td>\n      <td>2208.2334</td>\n      <td>1517.0152</td>\n      <td>1.0980</td>\n      <td>100.0</td>\n      <td>110.1900</td>\n      <td>0.1247</td>\n      <td>1.4357</td>\n      <td>0.0089</td>\n      <td>...</td>\n      <td>0.009000</td>\n      <td>64.240500</td>\n      <td>0.5016</td>\n      <td>0.0152</td>\n      <td>0.0040</td>\n      <td>3.0319</td>\n      <td>0.0465</td>\n      <td>0.0299</td>\n      <td>0.0090</td>\n      <td>64.2405</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2951.62</td>\n      <td>2511.92</td>\n      <td>2253.5111</td>\n      <td>1397.5060</td>\n      <td>0.9660</td>\n      <td>100.0</td>\n      <td>109.7611</td>\n      <td>0.1210</td>\n      <td>1.5527</td>\n      <td>0.0119</td>\n      <td>...</td>\n      <td>0.008100</td>\n      <td>0.000000</td>\n      <td>0.4953</td>\n      <td>0.0105</td>\n      <td>0.0037</td>\n      <td>2.1266</td>\n      <td>-0.0012</td>\n      <td>0.0252</td>\n      <td>0.0081</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2930.42</td>\n      <td>2505.17</td>\n      <td>2235.0556</td>\n      <td>1302.6607</td>\n      <td>1.6347</td>\n      <td>100.0</td>\n      <td>109.9856</td>\n      <td>0.1230</td>\n      <td>1.4588</td>\n      <td>-0.0143</td>\n      <td>...</td>\n      <td>0.004033</td>\n      <td>73.010633</td>\n      <td>0.4958</td>\n      <td>0.0111</td>\n      <td>0.0033</td>\n      <td>2.2296</td>\n      <td>-0.0012</td>\n      <td>0.0252</td>\n      <td>0.0081</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2997.28</td>\n      <td>2357.99</td>\n      <td>2141.0667</td>\n      <td>1236.5212</td>\n      <td>0.9698</td>\n      <td>100.0</td>\n      <td>98.3344</td>\n      <td>0.1238</td>\n      <td>1.5973</td>\n      <td>-0.0534</td>\n      <td>...</td>\n      <td>0.005067</td>\n      <td>51.803633</td>\n      <td>0.4962</td>\n      <td>0.0086</td>\n      <td>0.0024</td>\n      <td>1.7297</td>\n      <td>-0.0012</td>\n      <td>0.0252</td>\n      <td>0.0081</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3025.10</td>\n      <td>2475.18</td>\n      <td>2235.0556</td>\n      <td>1302.6607</td>\n      <td>1.6347</td>\n      <td>100.0</td>\n      <td>109.9856</td>\n      <td>0.1230</td>\n      <td>1.5525</td>\n      <td>-0.0078</td>\n      <td>...</td>\n      <td>0.005567</td>\n      <td>50.728767</td>\n      <td>0.4983</td>\n      <td>0.0159</td>\n      <td>0.0041</td>\n      <td>3.1927</td>\n      <td>-0.0012</td>\n      <td>0.0252</td>\n      <td>0.0081</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>2996.89</td>\n      <td>2492.40</td>\n      <td>2217.8667</td>\n      <td>1275.0917</td>\n      <td>1.5487</td>\n      <td>100.0</td>\n      <td>105.2933</td>\n      <td>0.1230</td>\n      <td>1.5455</td>\n      <td>-0.0140</td>\n      <td>...</td>\n      <td>0.004300</td>\n      <td>35.549600</td>\n      <td>0.5071</td>\n      <td>0.0123</td>\n      <td>0.0038</td>\n      <td>2.4294</td>\n      <td>0.0227</td>\n      <td>0.0149</td>\n      <td>0.0052</td>\n      <td>65.4831</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>2990.85</td>\n      <td>2485.99</td>\n      <td>2167.9444</td>\n      <td>861.8041</td>\n      <td>1.4140</td>\n      <td>100.0</td>\n      <td>106.6033</td>\n      <td>0.1243</td>\n      <td>1.4647</td>\n      <td>-0.0212</td>\n      <td>...</td>\n      <td>0.006167</td>\n      <td>52.293200</td>\n      <td>0.5015</td>\n      <td>0.0130</td>\n      <td>0.0042</td>\n      <td>2.5884</td>\n      <td>0.0227</td>\n      <td>0.0149</td>\n      <td>0.0052</td>\n      <td>65.4831</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>3059.43</td>\n      <td>2473.55</td>\n      <td>2214.9333</td>\n      <td>1663.7024</td>\n      <td>1.0203</td>\n      <td>100.0</td>\n      <td>100.4456</td>\n      <td>0.1247</td>\n      <td>1.4262</td>\n      <td>-0.0209</td>\n      <td>...</td>\n      <td>0.011400</td>\n      <td>108.607600</td>\n      <td>0.4973</td>\n      <td>0.0073</td>\n      <td>0.0017</td>\n      <td>1.4716</td>\n      <td>0.0300</td>\n      <td>0.0326</td>\n      <td>0.0114</td>\n      <td>108.6076</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>3024.54</td>\n      <td>2420.25</td>\n      <td>2167.9444</td>\n      <td>861.8041</td>\n      <td>1.4140</td>\n      <td>100.0</td>\n      <td>106.6033</td>\n      <td>0.1243</td>\n      <td>1.4849</td>\n      <td>-0.0072</td>\n      <td>...</td>\n      <td>0.006167</td>\n      <td>52.293200</td>\n      <td>0.5006</td>\n      <td>0.0068</td>\n      <td>0.0018</td>\n      <td>1.3667</td>\n      <td>0.0300</td>\n      <td>0.0326</td>\n      <td>0.0114</td>\n      <td>108.6076</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>3069.44</td>\n      <td>2459.50</td>\n      <td>2183.5000</td>\n      <td>1099.0027</td>\n      <td>1.3593</td>\n      <td>100.0</td>\n      <td>104.4156</td>\n      <td>0.1220</td>\n      <td>1.5549</td>\n      <td>-0.0130</td>\n      <td>...</td>\n      <td>0.003933</td>\n      <td>54.506233</td>\n      <td>0.5014</td>\n      <td>0.0090</td>\n      <td>0.0026</td>\n      <td>1.8039</td>\n      <td>0.0300</td>\n      <td>0.0326</td>\n      <td>0.0114</td>\n      <td>108.6076</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 574 columns</p>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"a=x.describe()\ncolumns=x.columns\ncolumns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T08:46:28.490941Z","iopub.execute_input":"2025-07-17T08:46:28.491366Z","iopub.status.idle":"2025-07-17T08:46:29.242576Z","shell.execute_reply.started":"2025-07-17T08:46:28.491334Z","shell.execute_reply":"2025-07-17T08:46:29.241156Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"RangeIndex(start=0, stop=574, step=1)"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"data_n = x.describe()\ndata_n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T08:46:37.395808Z","iopub.execute_input":"2025-07-17T08:46:37.396917Z","iopub.status.idle":"2025-07-17T08:46:38.139135Z","shell.execute_reply.started":"2025-07-17T08:46:37.396876Z","shell.execute_reply":"2025-07-17T08:46:38.138072Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"               0            1            2            3           4      5    \\\ncount   100.000000   100.000000   100.000000   100.000000  100.000000  100.0   \nmean   3003.614467  2504.110567  2187.307779  1193.136128    1.196562  100.0   \nstd      55.786124    83.501725    33.433605   196.895604    0.315792    0.0   \nmin    2890.670000  2158.750000  2113.077800   861.804100    0.802400  100.0   \n25%    2967.537500  2461.855000  2164.300000  1070.043900    0.879500  100.0   \n50%    2995.400000  2504.515000  2179.077800  1153.896950    1.290600  100.0   \n75%    3042.445000  2561.585000  2216.477800  1302.660700    1.486900  100.0   \nmax    3158.880000  2698.140000  2253.511100  1820.061300    1.775100  100.0   \n\n             6           7           8           9    ...         564  \\\ncount  100.00000  100.000000  100.000000  100.000000  ...  100.000000   \nmean   102.52551    0.123413    1.487260    0.000899  ...    0.005312   \nstd      4.17551    0.001539    0.060808    0.015851  ...    0.001414   \nmin     94.12560    0.119300    1.369800   -0.053400  ...    0.002100   \n25%    100.36330    0.122150    1.441025   -0.008900  ...    0.004425   \n50%    102.76885    0.123400    1.482750   -0.000600  ...    0.005267   \n75%    105.29330    0.124700    1.534825    0.009275  ...    0.006033   \nmax    110.54220    0.126500    1.605300    0.045500  ...    0.011400   \n\n              565         566         567         568         569         570  \\\ncount  100.000000  100.000000  100.000000  100.000000  100.000000  100.000000   \nmean    57.245810    0.500007    0.015468    0.003865    3.091090    0.023001   \nstd     15.742060    0.003733    0.006548    0.001267    1.296146    0.011036   \nmin      0.000000    0.492400    0.006800    0.001700    1.366700   -0.001200   \n25%     48.126067    0.496975    0.011750    0.003175    2.367300    0.018400   \n50%     54.803600    0.500400    0.014150    0.003600    2.814000    0.025200   \n75%     65.199000    0.502225    0.017325    0.004125    3.439000    0.033200   \nmax    108.607600    0.509800    0.046200    0.009900    9.184100    0.049200   \n\n              571         572         573  \ncount  100.000000  100.000000  100.000000  \nmean     0.017238    0.005513   57.579040  \nstd      0.005889    0.002113   26.622063  \nmin      0.007700    0.002100    0.000000  \n25%      0.012700    0.004000   40.253600  \n50%      0.015800    0.005150   65.483100  \n75%      0.019000    0.006000   73.865700  \nmax      0.032600    0.011400  108.607600  \n\n[8 rows x 574 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>564</th>\n      <th>565</th>\n      <th>566</th>\n      <th>567</th>\n      <th>568</th>\n      <th>569</th>\n      <th>570</th>\n      <th>571</th>\n      <th>572</th>\n      <th>573</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.0</td>\n      <td>100.00000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>...</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3003.614467</td>\n      <td>2504.110567</td>\n      <td>2187.307779</td>\n      <td>1193.136128</td>\n      <td>1.196562</td>\n      <td>100.0</td>\n      <td>102.52551</td>\n      <td>0.123413</td>\n      <td>1.487260</td>\n      <td>0.000899</td>\n      <td>...</td>\n      <td>0.005312</td>\n      <td>57.245810</td>\n      <td>0.500007</td>\n      <td>0.015468</td>\n      <td>0.003865</td>\n      <td>3.091090</td>\n      <td>0.023001</td>\n      <td>0.017238</td>\n      <td>0.005513</td>\n      <td>57.579040</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>55.786124</td>\n      <td>83.501725</td>\n      <td>33.433605</td>\n      <td>196.895604</td>\n      <td>0.315792</td>\n      <td>0.0</td>\n      <td>4.17551</td>\n      <td>0.001539</td>\n      <td>0.060808</td>\n      <td>0.015851</td>\n      <td>...</td>\n      <td>0.001414</td>\n      <td>15.742060</td>\n      <td>0.003733</td>\n      <td>0.006548</td>\n      <td>0.001267</td>\n      <td>1.296146</td>\n      <td>0.011036</td>\n      <td>0.005889</td>\n      <td>0.002113</td>\n      <td>26.622063</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>2890.670000</td>\n      <td>2158.750000</td>\n      <td>2113.077800</td>\n      <td>861.804100</td>\n      <td>0.802400</td>\n      <td>100.0</td>\n      <td>94.12560</td>\n      <td>0.119300</td>\n      <td>1.369800</td>\n      <td>-0.053400</td>\n      <td>...</td>\n      <td>0.002100</td>\n      <td>0.000000</td>\n      <td>0.492400</td>\n      <td>0.006800</td>\n      <td>0.001700</td>\n      <td>1.366700</td>\n      <td>-0.001200</td>\n      <td>0.007700</td>\n      <td>0.002100</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2967.537500</td>\n      <td>2461.855000</td>\n      <td>2164.300000</td>\n      <td>1070.043900</td>\n      <td>0.879500</td>\n      <td>100.0</td>\n      <td>100.36330</td>\n      <td>0.122150</td>\n      <td>1.441025</td>\n      <td>-0.008900</td>\n      <td>...</td>\n      <td>0.004425</td>\n      <td>48.126067</td>\n      <td>0.496975</td>\n      <td>0.011750</td>\n      <td>0.003175</td>\n      <td>2.367300</td>\n      <td>0.018400</td>\n      <td>0.012700</td>\n      <td>0.004000</td>\n      <td>40.253600</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2995.400000</td>\n      <td>2504.515000</td>\n      <td>2179.077800</td>\n      <td>1153.896950</td>\n      <td>1.290600</td>\n      <td>100.0</td>\n      <td>102.76885</td>\n      <td>0.123400</td>\n      <td>1.482750</td>\n      <td>-0.000600</td>\n      <td>...</td>\n      <td>0.005267</td>\n      <td>54.803600</td>\n      <td>0.500400</td>\n      <td>0.014150</td>\n      <td>0.003600</td>\n      <td>2.814000</td>\n      <td>0.025200</td>\n      <td>0.015800</td>\n      <td>0.005150</td>\n      <td>65.483100</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3042.445000</td>\n      <td>2561.585000</td>\n      <td>2216.477800</td>\n      <td>1302.660700</td>\n      <td>1.486900</td>\n      <td>100.0</td>\n      <td>105.29330</td>\n      <td>0.124700</td>\n      <td>1.534825</td>\n      <td>0.009275</td>\n      <td>...</td>\n      <td>0.006033</td>\n      <td>65.199000</td>\n      <td>0.502225</td>\n      <td>0.017325</td>\n      <td>0.004125</td>\n      <td>3.439000</td>\n      <td>0.033200</td>\n      <td>0.019000</td>\n      <td>0.006000</td>\n      <td>73.865700</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3158.880000</td>\n      <td>2698.140000</td>\n      <td>2253.511100</td>\n      <td>1820.061300</td>\n      <td>1.775100</td>\n      <td>100.0</td>\n      <td>110.54220</td>\n      <td>0.126500</td>\n      <td>1.605300</td>\n      <td>0.045500</td>\n      <td>...</td>\n      <td>0.011400</td>\n      <td>108.607600</td>\n      <td>0.509800</td>\n      <td>0.046200</td>\n      <td>0.009900</td>\n      <td>9.184100</td>\n      <td>0.049200</td>\n      <td>0.032600</td>\n      <td>0.011400</td>\n      <td>108.607600</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 574 columns</p>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"Κάνε έλεγχο για στήλες που δεν συνεισφέρουν στην πρόβλεψη. Αν η τυπική απόκλιση μιας στήλης είναι μηδέν, σημαίνει ότι έχει σταθερές τιμές και δίνει το ίδιο αποτέλεσμα τόσο για καλούς όσο και για χαλασμένους αισθητήρες. Ετοίμασε τη λίστα με αυτές τις στήλες για να διαγραφούν.","metadata":{}},{"cell_type":"code","source":"columns=x.columns\ndata_n = x.describe()\ncol_to_drop=[]\nfor a in columns:\n    if (data_n[a]['std'] == 0): # check if standard deviation is zero\n        col_to_drop.append(a)# prepare the list of columns with standard deviation zero\ncol_to_drop #the list of columns with standard deviation zero","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T08:46:54.699176Z","iopub.execute_input":"2025-07-17T08:46:54.699532Z","iopub.status.idle":"2025-07-17T08:46:55.533926Z","shell.execute_reply.started":"2025-07-17T08:46:54.699498Z","shell.execute_reply":"2025-07-17T08:46:55.533047Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"[5,\n 13,\n 42,\n 49,\n 52,\n 69,\n 74,\n 96,\n 137,\n 145,\n 174,\n 175,\n 182,\n 185,\n 186,\n 187,\n 188,\n 189,\n 190,\n 202,\n 205,\n 221,\n 224,\n 225,\n 226,\n 227,\n 228,\n 229,\n 230,\n 231,\n 232,\n 235,\n 236,\n 237,\n 238,\n 248,\n 249,\n 250,\n 251,\n 252,\n 253,\n 254,\n 255,\n 256,\n 257,\n 258,\n 268,\n 276,\n 305,\n 306,\n 307,\n 314,\n 317,\n 318,\n 319,\n 320,\n 321,\n 322,\n 334,\n 339,\n 355,\n 360,\n 361,\n 362,\n 363,\n 364,\n 365,\n 366,\n 369,\n 370,\n 371,\n 372,\n 382,\n 383,\n 384,\n 385,\n 386,\n 387,\n 388,\n 389,\n 390,\n 391,\n 392,\n 402,\n 410,\n 437,\n 438,\n 439,\n 446,\n 449,\n 450,\n 451,\n 452,\n 453,\n 454,\n 466,\n 469,\n 485,\n 488,\n 489,\n 490,\n 491,\n 492,\n 493,\n 494,\n 495,\n 496,\n 499,\n 500,\n 501,\n 502,\n 505,\n 512,\n 513,\n 514,\n 515,\n 516,\n 517,\n 518,\n 519,\n 520,\n 521,\n 522]"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"! pip install kneed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T08:48:30.997842Z","iopub.execute_input":"2025-07-17T08:48:30.998176Z","iopub.status.idle":"2025-07-17T08:48:36.863460Z","shell.execute_reply.started":"2025-07-17T08:48:30.998155Z","shell.execute_reply":"2025-07-17T08:48:36.862092Z"}},"outputs":[{"name":"stdout","text":"Collecting kneed\n  Downloading kneed-0.8.5-py3-none-any.whl.metadata (5.5 kB)\nRequirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from kneed) (1.26.4)\nRequirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from kneed) (1.15.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.2->kneed) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.2->kneed) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.2->kneed) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.2->kneed) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.2->kneed) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.2->kneed) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.2->kneed) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.2->kneed) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.2->kneed) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.14.2->kneed) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.14.2->kneed) (2024.2.0)\nDownloading kneed-0.8.5-py3-none-any.whl (10 kB)\nInstalling collected packages: kneed\nSuccessfully installed kneed-0.8.5\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"Η βιβλιοθήκη kneed είναι ένα εργαλείο της Python που χρησιμοποιείται για να βρίσκουμε το \"γόνατο\" (knee) ή \"αγκώνα\" (elbow) σε μια καμπύλη — δηλαδή το σημείο όπου η καμπύλη αλλάζει απότομα πορεία. Χρησιμοποιείται συχνά σε προβλήματα όπου θέλουμε να βρούμε το ιδανικό σημείο ισορροπίας, π.χ.:\n\n📌 Πού χρησιμοποιείται το kneed:\n🔹 1. Elbow Method στο K-Means Clustering\nΌταν επιλέγουμε τον ιδανικό αριθμό των clusters:\n\nΦτιάχνουμε ένα γράφημα με αριθμό clusters vs inertia (σφάλμα).\n\nΤο \"γόνατο\" της καμπύλης είναι το ιδανικό σημείο — και η βιβλιοθήκη kneed μπορεί να το εντοπίσει αυτόματα.","metadata":{}},{"cell_type":"code","source":"from kneed import KneeLocator   #! pip install kneed\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T08:48:52.328130Z","iopub.execute_input":"2025-07-17T08:48:52.328962Z","iopub.status.idle":"2025-07-17T08:48:52.547063Z","shell.execute_reply.started":"2025-07-17T08:48:52.328925Z","shell.execute_reply":"2025-07-17T08:48:52.546056Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"wcss =[]\nfor i in range (1,11):\n    kmeans=KMeans(n_clusters=i,init='k-means++',random_state=42) # initializing the KMeans object\n    kmeans.fit(x) # fitting the data to the KMeans Algorithm\n    wcss.append(kmeans.inertia_)\nplt.plot(range(1,11),wcss) # creating the graph between WCSS and the number of clusters\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\n#plt.show()\nplt.savefig('K-Means_Elbow.PNG') # saving the elbow plot locally","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T08:49:34.655634Z","iopub.execute_input":"2025-07-17T08:49:34.656489Z","iopub.status.idle":"2025-07-17T08:49:35.618068Z","shell.execute_reply.started":"2025-07-17T08:49:34.656462Z","shell.execute_reply":"2025-07-17T08:49:35.617022Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"kn = KneeLocator(range(1, 11), wcss, curve='convex', direction='decreasing')\nnumber_of_clusters=kn.knee #  using the elbow plot to find the number of optimum clusters\nnumber_of_clusters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T08:49:47.695409Z","iopub.execute_input":"2025-07-17T08:49:47.696766Z","iopub.status.idle":"2025-07-17T08:49:47.704898Z","shell.execute_reply.started":"2025-07-17T08:49:47.696730Z","shell.execute_reply":"2025-07-17T08:49:47.703759Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"3"},"metadata":{}}],"execution_count":25},{"cell_type":"markdown","source":"βρίσκεις τον ιδανικό αριθμό clusters (ομάδων) που πρέπει να χρησιμοποιήσεις σε έναν αλγόριθμο ομαδοποίησης, όπως το K-Means.","metadata":{}},{"cell_type":"code","source":"kmeans = KMeans(n_clusters=number_of_clusters, init='k-means++', random_state=42)\ny_kmeans=kmeans.fit_predict(x) #  divide data into clusters\ny_kmeans","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T08:50:42.690982Z","iopub.execute_input":"2025-07-17T08:50:42.692465Z","iopub.status.idle":"2025-07-17T08:50:42.751640Z","shell.execute_reply.started":"2025-07-17T08:50:42.692413Z","shell.execute_reply":"2025-07-17T08:50:42.750722Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"array([1, 0, 0, 0, 2, 0, 1, 0, 2, 0, 0, 1, 0, 2, 1, 1, 0, 0, 2, 0, 1, 2,\n       1, 0, 0, 1, 2, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2,\n       0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 1, 1, 0, 0, 1, 2, 0, 0, 1,\n       0, 2, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n       0, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0], dtype=int32)"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"import pickle\npickle.dump(kmeans, open(\"KMeans.sav\", 'wb'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T08:50:57.475298Z","iopub.execute_input":"2025-07-17T08:50:57.475903Z","iopub.status.idle":"2025-07-17T08:50:57.483484Z","shell.execute_reply.started":"2025-07-17T08:50:57.475866Z","shell.execute_reply":"2025-07-17T08:50:57.482053Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"x['Cluster']=y_kmeans \nx[\"Cluster\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T08:51:13.439914Z","iopub.execute_input":"2025-07-17T08:51:13.440251Z","iopub.status.idle":"2025-07-17T08:51:13.450679Z","shell.execute_reply.started":"2025-07-17T08:51:13.440210Z","shell.execute_reply":"2025-07-17T08:51:13.449702Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"0     1\n1     0\n2     0\n3     0\n4     2\n     ..\n95    2\n96    0\n97    0\n98    0\n99    0\nName: Cluster, Length: 100, dtype: int32"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"x['Labels']=y\nx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T08:51:33.920104Z","iopub.execute_input":"2025-07-17T08:51:33.920446Z","iopub.status.idle":"2025-07-17T08:51:33.956928Z","shell.execute_reply.started":"2025-07-17T08:51:33.920424Z","shell.execute_reply":"2025-07-17T08:51:33.955581Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"          0        1          2          3       4      5         6       7  \\\n0   3076.81  2158.75  2208.2334  1517.0152  1.0980  100.0  110.1900  0.1247   \n1   2951.62  2511.92  2253.5111  1397.5060  0.9660  100.0  109.7611  0.1210   \n2   2930.42  2505.17  2235.0556  1302.6607  1.6347  100.0  109.9856  0.1230   \n3   2997.28  2357.99  2141.0667  1236.5212  0.9698  100.0   98.3344  0.1238   \n4   3025.10  2475.18  2235.0556  1302.6607  1.6347  100.0  109.9856  0.1230   \n..      ...      ...        ...        ...     ...    ...       ...     ...   \n95  2996.89  2492.40  2217.8667  1275.0917  1.5487  100.0  105.2933  0.1230   \n96  2990.85  2485.99  2167.9444   861.8041  1.4140  100.0  106.6033  0.1243   \n97  3059.43  2473.55  2214.9333  1663.7024  1.0203  100.0  100.4456  0.1247   \n98  3024.54  2420.25  2167.9444   861.8041  1.4140  100.0  106.6033  0.1243   \n99  3069.44  2459.50  2183.5000  1099.0027  1.3593  100.0  104.4156  0.1220   \n\n         8       9  ...     566     567     568     569     570     571  \\\n0   1.4357  0.0089  ...  0.5016  0.0152  0.0040  3.0319  0.0465  0.0299   \n1   1.5527  0.0119  ...  0.4953  0.0105  0.0037  2.1266 -0.0012  0.0252   \n2   1.4588 -0.0143  ...  0.4958  0.0111  0.0033  2.2296 -0.0012  0.0252   \n3   1.5973 -0.0534  ...  0.4962  0.0086  0.0024  1.7297 -0.0012  0.0252   \n4   1.5525 -0.0078  ...  0.4983  0.0159  0.0041  3.1927 -0.0012  0.0252   \n..     ...     ...  ...     ...     ...     ...     ...     ...     ...   \n95  1.5455 -0.0140  ...  0.5071  0.0123  0.0038  2.4294  0.0227  0.0149   \n96  1.4647 -0.0212  ...  0.5015  0.0130  0.0042  2.5884  0.0227  0.0149   \n97  1.4262 -0.0209  ...  0.4973  0.0073  0.0017  1.4716  0.0300  0.0326   \n98  1.4849 -0.0072  ...  0.5006  0.0068  0.0018  1.3667  0.0300  0.0326   \n99  1.5549 -0.0130  ...  0.5014  0.0090  0.0026  1.8039  0.0300  0.0326   \n\n       572       573  Cluster  Labels  \n0   0.0090   64.2405        1      -1  \n1   0.0081    0.0000        0      -1  \n2   0.0081    0.0000        0      -1  \n3   0.0081    0.0000        0      -1  \n4   0.0081    0.0000        2      -1  \n..     ...       ...      ...     ...  \n95  0.0052   65.4831        2      -1  \n96  0.0052   65.4831        0      -1  \n97  0.0114  108.6076        0      -1  \n98  0.0114  108.6076        0      -1  \n99  0.0114  108.6076        0      -1  \n\n[100 rows x 576 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>566</th>\n      <th>567</th>\n      <th>568</th>\n      <th>569</th>\n      <th>570</th>\n      <th>571</th>\n      <th>572</th>\n      <th>573</th>\n      <th>Cluster</th>\n      <th>Labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3076.81</td>\n      <td>2158.75</td>\n      <td>2208.2334</td>\n      <td>1517.0152</td>\n      <td>1.0980</td>\n      <td>100.0</td>\n      <td>110.1900</td>\n      <td>0.1247</td>\n      <td>1.4357</td>\n      <td>0.0089</td>\n      <td>...</td>\n      <td>0.5016</td>\n      <td>0.0152</td>\n      <td>0.0040</td>\n      <td>3.0319</td>\n      <td>0.0465</td>\n      <td>0.0299</td>\n      <td>0.0090</td>\n      <td>64.2405</td>\n      <td>1</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2951.62</td>\n      <td>2511.92</td>\n      <td>2253.5111</td>\n      <td>1397.5060</td>\n      <td>0.9660</td>\n      <td>100.0</td>\n      <td>109.7611</td>\n      <td>0.1210</td>\n      <td>1.5527</td>\n      <td>0.0119</td>\n      <td>...</td>\n      <td>0.4953</td>\n      <td>0.0105</td>\n      <td>0.0037</td>\n      <td>2.1266</td>\n      <td>-0.0012</td>\n      <td>0.0252</td>\n      <td>0.0081</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2930.42</td>\n      <td>2505.17</td>\n      <td>2235.0556</td>\n      <td>1302.6607</td>\n      <td>1.6347</td>\n      <td>100.0</td>\n      <td>109.9856</td>\n      <td>0.1230</td>\n      <td>1.4588</td>\n      <td>-0.0143</td>\n      <td>...</td>\n      <td>0.4958</td>\n      <td>0.0111</td>\n      <td>0.0033</td>\n      <td>2.2296</td>\n      <td>-0.0012</td>\n      <td>0.0252</td>\n      <td>0.0081</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2997.28</td>\n      <td>2357.99</td>\n      <td>2141.0667</td>\n      <td>1236.5212</td>\n      <td>0.9698</td>\n      <td>100.0</td>\n      <td>98.3344</td>\n      <td>0.1238</td>\n      <td>1.5973</td>\n      <td>-0.0534</td>\n      <td>...</td>\n      <td>0.4962</td>\n      <td>0.0086</td>\n      <td>0.0024</td>\n      <td>1.7297</td>\n      <td>-0.0012</td>\n      <td>0.0252</td>\n      <td>0.0081</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3025.10</td>\n      <td>2475.18</td>\n      <td>2235.0556</td>\n      <td>1302.6607</td>\n      <td>1.6347</td>\n      <td>100.0</td>\n      <td>109.9856</td>\n      <td>0.1230</td>\n      <td>1.5525</td>\n      <td>-0.0078</td>\n      <td>...</td>\n      <td>0.4983</td>\n      <td>0.0159</td>\n      <td>0.0041</td>\n      <td>3.1927</td>\n      <td>-0.0012</td>\n      <td>0.0252</td>\n      <td>0.0081</td>\n      <td>0.0000</td>\n      <td>2</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>2996.89</td>\n      <td>2492.40</td>\n      <td>2217.8667</td>\n      <td>1275.0917</td>\n      <td>1.5487</td>\n      <td>100.0</td>\n      <td>105.2933</td>\n      <td>0.1230</td>\n      <td>1.5455</td>\n      <td>-0.0140</td>\n      <td>...</td>\n      <td>0.5071</td>\n      <td>0.0123</td>\n      <td>0.0038</td>\n      <td>2.4294</td>\n      <td>0.0227</td>\n      <td>0.0149</td>\n      <td>0.0052</td>\n      <td>65.4831</td>\n      <td>2</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>2990.85</td>\n      <td>2485.99</td>\n      <td>2167.9444</td>\n      <td>861.8041</td>\n      <td>1.4140</td>\n      <td>100.0</td>\n      <td>106.6033</td>\n      <td>0.1243</td>\n      <td>1.4647</td>\n      <td>-0.0212</td>\n      <td>...</td>\n      <td>0.5015</td>\n      <td>0.0130</td>\n      <td>0.0042</td>\n      <td>2.5884</td>\n      <td>0.0227</td>\n      <td>0.0149</td>\n      <td>0.0052</td>\n      <td>65.4831</td>\n      <td>0</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>3059.43</td>\n      <td>2473.55</td>\n      <td>2214.9333</td>\n      <td>1663.7024</td>\n      <td>1.0203</td>\n      <td>100.0</td>\n      <td>100.4456</td>\n      <td>0.1247</td>\n      <td>1.4262</td>\n      <td>-0.0209</td>\n      <td>...</td>\n      <td>0.4973</td>\n      <td>0.0073</td>\n      <td>0.0017</td>\n      <td>1.4716</td>\n      <td>0.0300</td>\n      <td>0.0326</td>\n      <td>0.0114</td>\n      <td>108.6076</td>\n      <td>0</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>3024.54</td>\n      <td>2420.25</td>\n      <td>2167.9444</td>\n      <td>861.8041</td>\n      <td>1.4140</td>\n      <td>100.0</td>\n      <td>106.6033</td>\n      <td>0.1243</td>\n      <td>1.4849</td>\n      <td>-0.0072</td>\n      <td>...</td>\n      <td>0.5006</td>\n      <td>0.0068</td>\n      <td>0.0018</td>\n      <td>1.3667</td>\n      <td>0.0300</td>\n      <td>0.0326</td>\n      <td>0.0114</td>\n      <td>108.6076</td>\n      <td>0</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>3069.44</td>\n      <td>2459.50</td>\n      <td>2183.5000</td>\n      <td>1099.0027</td>\n      <td>1.3593</td>\n      <td>100.0</td>\n      <td>104.4156</td>\n      <td>0.1220</td>\n      <td>1.5549</td>\n      <td>-0.0130</td>\n      <td>...</td>\n      <td>0.5014</td>\n      <td>0.0090</td>\n      <td>0.0026</td>\n      <td>1.8039</td>\n      <td>0.0300</td>\n      <td>0.0326</td>\n      <td>0.0114</td>\n      <td>108.6076</td>\n      <td>0</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 576 columns</p>\n</div>"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"list_of_clusters=x['Cluster'].unique() # getting the unique clusters from our dataset\nlist_of_clusters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T08:51:46.887444Z","iopub.execute_input":"2025-07-17T08:51:46.888092Z","iopub.status.idle":"2025-07-17T08:51:46.897909Z","shell.execute_reply.started":"2025-07-17T08:51:46.888062Z","shell.execute_reply":"2025-07-17T08:51:46.896451Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"array([1, 0, 2], dtype=int32)"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"for i in list_of_clusters:\n    cluster_data=x[x['Cluster']==i] # filter the data for one cluster\n\n    # Prepare the feature and Label columns\n    cluster_features=cluster_data.drop(['Labels','Cluster'],axis=1)\n    cluster_label= cluster_data['Labels']\n\n    # splitting the data into training and test set for each cluster one by one\n    x_train, x_test, y_train, y_test = train_test_split(cluster_features, cluster_label, test_size=1 / 3, random_state=355)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T08:51:58.641309Z","iopub.execute_input":"2025-07-17T08:51:58.641631Z","iopub.status.idle":"2025-07-17T08:51:58.658096Z","shell.execute_reply.started":"2025-07-17T08:51:58.641610Z","shell.execute_reply":"2025-07-17T08:51:58.656995Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"xgb = XGBClassifier(objective='binary:logistic')\n### Initializing with different combination of parameters\nparam_grid_xgboost = {\n\n                'learning_rate': [0.5, 0.1, 0.01, 0.001],\n                'max_depth': [3, 5, 10, 20],\n                'n_estimators': [10, 50, 100, 200]\n\n            } \n### Creating an object of the Grid Search class\ngrid2= GridSearchCV(XGBClassifier(objective='binary:logistic'),param_grid_xgboost, verbose=3,cv=5)          \ngrid2.fit(x_train, y_train)# finding the best parameters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:12:52.917086Z","iopub.execute_input":"2025-07-17T09:12:52.917559Z","iopub.status.idle":"2025-07-17T09:13:12.846261Z","shell.execute_reply.started":"2025-07-17T09:12:52.917531Z","shell.execute_reply":"2025-07-17T09:13:12.845339Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 64 candidates, totalling 320 fits\n[CV 1/5] END learning_rate=0.5, max_depth=3, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 2/5] END learning_rate=0.5, max_depth=3, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 3/5] END learning_rate=0.5, max_depth=3, n_estimators=10;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.5, max_depth=3, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.5, max_depth=3, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 2/5] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 3/5] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.5, max_depth=3, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.5, max_depth=3, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.5, max_depth=3, n_estimators=100;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.5, max_depth=3, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 5/5] END learning_rate=0.5, max_depth=3, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.5, max_depth=3, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.5, max_depth=3, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.5, max_depth=3, n_estimators=200;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.5, max_depth=3, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 5/5] END learning_rate=0.5, max_depth=3, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.5, max_depth=5, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 2/5] END learning_rate=0.5, max_depth=5, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 3/5] END learning_rate=0.5, max_depth=5, n_estimators=10;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.5, max_depth=5, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.5, max_depth=5, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 2/5] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 3/5] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.5, max_depth=5, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.5, max_depth=5, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.5, max_depth=5, n_estimators=100;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.5, max_depth=5, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 5/5] END learning_rate=0.5, max_depth=5, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.5, max_depth=5, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.5, max_depth=5, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.5, max_depth=5, n_estimators=200;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.5, max_depth=5, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 5/5] END learning_rate=0.5, max_depth=5, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.5, max_depth=10, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 2/5] END learning_rate=0.5, max_depth=10, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 3/5] END learning_rate=0.5, max_depth=10, n_estimators=10;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.5, max_depth=10, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.5, max_depth=10, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.5, max_depth=10, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 2/5] END learning_rate=0.5, max_depth=10, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 3/5] END learning_rate=0.5, max_depth=10, n_estimators=50;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.5, max_depth=10, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.5, max_depth=10, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.5, max_depth=10, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.5, max_depth=10, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.5, max_depth=10, n_estimators=100;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.5, max_depth=10, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 5/5] END learning_rate=0.5, max_depth=10, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.5, max_depth=10, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.5, max_depth=10, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.5, max_depth=10, n_estimators=200;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.5, max_depth=10, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 5/5] END learning_rate=0.5, max_depth=10, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.5, max_depth=20, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 2/5] END learning_rate=0.5, max_depth=20, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 3/5] END learning_rate=0.5, max_depth=20, n_estimators=10;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.5, max_depth=20, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.5, max_depth=20, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.5, max_depth=20, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 2/5] END learning_rate=0.5, max_depth=20, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 3/5] END learning_rate=0.5, max_depth=20, n_estimators=50;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.5, max_depth=20, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.5, max_depth=20, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.5, max_depth=20, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.5, max_depth=20, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.5, max_depth=20, n_estimators=100;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.5, max_depth=20, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 5/5] END learning_rate=0.5, max_depth=20, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.5, max_depth=20, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.5, max_depth=20, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.5, max_depth=20, n_estimators=200;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.5, max_depth=20, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 5/5] END learning_rate=0.5, max_depth=20, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=10;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=10;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=10;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=50;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=50;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=200;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.1, max_depth=20, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.1, max_depth=20, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.1, max_depth=20, n_estimators=10;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.1, max_depth=20, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.1, max_depth=20, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.1, max_depth=20, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 2/5] END learning_rate=0.1, max_depth=20, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 3/5] END learning_rate=0.1, max_depth=20, n_estimators=50;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.1, max_depth=20, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.1, max_depth=20, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.1, max_depth=20, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.1, max_depth=20, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.1, max_depth=20, n_estimators=100;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.1, max_depth=20, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.1, max_depth=20, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.1, max_depth=20, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.1, max_depth=20, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.1, max_depth=20, n_estimators=200;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.1, max_depth=20, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.1, max_depth=20, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=10;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=10;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=50;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=0.792 total time=   0.1s\n[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=1.000 total time=   0.2s\n[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=10;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=10;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=50;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=50;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=0.792 total time=   0.1s\n[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=10;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=10;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=50;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=50;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=100;, score=0.792 total time=   0.1s\n[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=200;, score=0.958 total time=   0.2s\n[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=200;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.01, max_depth=20, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.01, max_depth=20, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.01, max_depth=20, n_estimators=10;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.01, max_depth=20, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.01, max_depth=20, n_estimators=10;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.01, max_depth=20, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.01, max_depth=20, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.01, max_depth=20, n_estimators=50;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.01, max_depth=20, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.01, max_depth=20, n_estimators=50;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.01, max_depth=20, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 2/5] END learning_rate=0.01, max_depth=20, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 3/5] END learning_rate=0.01, max_depth=20, n_estimators=100;, score=0.792 total time=   0.1s\n[CV 4/5] END learning_rate=0.01, max_depth=20, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.01, max_depth=20, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.01, max_depth=20, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.01, max_depth=20, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 3/5] END learning_rate=0.01, max_depth=20, n_estimators=200;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.01, max_depth=20, n_estimators=200;, score=0.958 total time=   0.2s\n[CV 5/5] END learning_rate=0.01, max_depth=20, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.001, max_depth=3, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.001, max_depth=3, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.001, max_depth=3, n_estimators=10;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.001, max_depth=3, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.001, max_depth=3, n_estimators=10;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.001, max_depth=3, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.001, max_depth=3, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.001, max_depth=3, n_estimators=50;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.001, max_depth=3, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.001, max_depth=3, n_estimators=50;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.001, max_depth=3, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 2/5] END learning_rate=0.001, max_depth=3, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 3/5] END learning_rate=0.001, max_depth=3, n_estimators=100;, score=0.792 total time=   0.1s\n[CV 4/5] END learning_rate=0.001, max_depth=3, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.001, max_depth=3, n_estimators=100;, score=0.917 total time=   0.1s\n[CV 1/5] END learning_rate=0.001, max_depth=3, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 2/5] END learning_rate=0.001, max_depth=3, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 3/5] END learning_rate=0.001, max_depth=3, n_estimators=200;, score=0.792 total time=   0.1s\n[CV 4/5] END learning_rate=0.001, max_depth=3, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.001, max_depth=3, n_estimators=200;, score=0.917 total time=   0.1s\n[CV 1/5] END learning_rate=0.001, max_depth=5, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.001, max_depth=5, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.001, max_depth=5, n_estimators=10;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.001, max_depth=5, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.001, max_depth=5, n_estimators=10;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.001, max_depth=5, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.001, max_depth=5, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.001, max_depth=5, n_estimators=50;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.001, max_depth=5, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.001, max_depth=5, n_estimators=50;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.001, max_depth=5, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 2/5] END learning_rate=0.001, max_depth=5, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 3/5] END learning_rate=0.001, max_depth=5, n_estimators=100;, score=0.792 total time=   0.1s\n[CV 4/5] END learning_rate=0.001, max_depth=5, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.001, max_depth=5, n_estimators=100;, score=0.917 total time=   0.1s\n[CV 1/5] END learning_rate=0.001, max_depth=5, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 2/5] END learning_rate=0.001, max_depth=5, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 3/5] END learning_rate=0.001, max_depth=5, n_estimators=200;, score=0.792 total time=   0.1s\n[CV 4/5] END learning_rate=0.001, max_depth=5, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.001, max_depth=5, n_estimators=200;, score=0.917 total time=   0.1s\n[CV 1/5] END learning_rate=0.001, max_depth=10, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.001, max_depth=10, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.001, max_depth=10, n_estimators=10;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.001, max_depth=10, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.001, max_depth=10, n_estimators=10;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.001, max_depth=10, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.001, max_depth=10, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.001, max_depth=10, n_estimators=50;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.001, max_depth=10, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.001, max_depth=10, n_estimators=50;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.001, max_depth=10, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 2/5] END learning_rate=0.001, max_depth=10, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 3/5] END learning_rate=0.001, max_depth=10, n_estimators=100;, score=0.792 total time=   0.1s\n[CV 4/5] END learning_rate=0.001, max_depth=10, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.001, max_depth=10, n_estimators=100;, score=0.917 total time=   0.1s\n[CV 1/5] END learning_rate=0.001, max_depth=10, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 2/5] END learning_rate=0.001, max_depth=10, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 3/5] END learning_rate=0.001, max_depth=10, n_estimators=200;, score=0.792 total time=   0.1s\n[CV 4/5] END learning_rate=0.001, max_depth=10, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.001, max_depth=10, n_estimators=200;, score=0.917 total time=   0.1s\n[CV 1/5] END learning_rate=0.001, max_depth=20, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.001, max_depth=20, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.001, max_depth=20, n_estimators=10;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.001, max_depth=20, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.001, max_depth=20, n_estimators=10;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.001, max_depth=20, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.001, max_depth=20, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.001, max_depth=20, n_estimators=50;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.001, max_depth=20, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.001, max_depth=20, n_estimators=50;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.001, max_depth=20, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 2/5] END learning_rate=0.001, max_depth=20, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 3/5] END learning_rate=0.001, max_depth=20, n_estimators=100;, score=0.792 total time=   0.1s\n[CV 4/5] END learning_rate=0.001, max_depth=20, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.001, max_depth=20, n_estimators=100;, score=0.917 total time=   0.1s\n[CV 1/5] END learning_rate=0.001, max_depth=20, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 2/5] END learning_rate=0.001, max_depth=20, n_estimators=200;, score=1.000 total time=   0.2s\n[CV 3/5] END learning_rate=0.001, max_depth=20, n_estimators=200;, score=0.792 total time=   0.1s\n[CV 4/5] END learning_rate=0.001, max_depth=20, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.001, max_depth=20, n_estimators=200;, score=0.917 total time=   0.1s\n","output_type":"stream"},{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"GridSearchCV(cv=5,\n             estimator=XGBClassifier(base_score=None, booster=None,\n                                     callbacks=None, colsample_bylevel=None,\n                                     colsample_bynode=None,\n                                     colsample_bytree=None, device=None,\n                                     early_stopping_rounds=None,\n                                     enable_categorical=False, eval_metric=None,\n                                     feature_types=None, gamma=None,\n                                     grow_policy=None, importance_type=None,\n                                     interaction_constraints=None,\n                                     learning_rate=None,...\n                                     max_cat_threshold=None,\n                                     max_cat_to_onehot=None,\n                                     max_delta_step=None, max_depth=None,\n                                     max_leaves=None, min_child_weight=None,\n                                     missing=nan, monotone_constraints=None,\n                                     multi_strategy=None, n_estimators=None,\n                                     n_jobs=None, num_parallel_tree=None,\n                                     random_state=None, ...),\n             param_grid={'learning_rate': [0.5, 0.1, 0.01, 0.001],\n                         'max_depth': [3, 5, 10, 20],\n                         'n_estimators': [10, 50, 100, 200]},\n             verbose=3)","text/html":"<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n             estimator=XGBClassifier(base_score=None, booster=None,\n                                     callbacks=None, colsample_bylevel=None,\n                                     colsample_bynode=None,\n                                     colsample_bytree=None, device=None,\n                                     early_stopping_rounds=None,\n                                     enable_categorical=False, eval_metric=None,\n                                     feature_types=None, gamma=None,\n                                     grow_policy=None, importance_type=None,\n                                     interaction_constraints=None,\n                                     learning_rate=None,...\n                                     max_cat_threshold=None,\n                                     max_cat_to_onehot=None,\n                                     max_delta_step=None, max_depth=None,\n                                     max_leaves=None, min_child_weight=None,\n                                     missing=nan, monotone_constraints=None,\n                                     multi_strategy=None, n_estimators=None,\n                                     n_jobs=None, num_parallel_tree=None,\n                                     random_state=None, ...),\n             param_grid={&#x27;learning_rate&#x27;: [0.5, 0.1, 0.01, 0.001],\n                         &#x27;max_depth&#x27;: [3, 5, 10, 20],\n                         &#x27;n_estimators&#x27;: [10, 50, 100, 200]},\n             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n             estimator=XGBClassifier(base_score=None, booster=None,\n                                     callbacks=None, colsample_bylevel=None,\n                                     colsample_bynode=None,\n                                     colsample_bytree=None, device=None,\n                                     early_stopping_rounds=None,\n                                     enable_categorical=False, eval_metric=None,\n                                     feature_types=None, gamma=None,\n                                     grow_policy=None, importance_type=None,\n                                     interaction_constraints=None,\n                                     learning_rate=None,...\n                                     max_cat_threshold=None,\n                                     max_cat_to_onehot=None,\n                                     max_delta_step=None, max_depth=None,\n                                     max_leaves=None, min_child_weight=None,\n                                     missing=nan, monotone_constraints=None,\n                                     multi_strategy=None, n_estimators=None,\n                                     n_jobs=None, num_parallel_tree=None,\n                                     random_state=None, ...),\n             param_grid={&#x27;learning_rate&#x27;: [0.5, 0.1, 0.01, 0.001],\n                         &#x27;max_depth&#x27;: [3, 5, 10, 20],\n                         &#x27;n_estimators&#x27;: [10, 50, 100, 200]},\n             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":69},{"cell_type":"code","source":"grid2.fit(x_train, y_train)# finding the best parameters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:13:37.042147Z","iopub.execute_input":"2025-07-17T09:13:37.042539Z","iopub.status.idle":"2025-07-17T09:13:59.564264Z","shell.execute_reply.started":"2025-07-17T09:13:37.042515Z","shell.execute_reply":"2025-07-17T09:13:59.563381Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 64 candidates, totalling 320 fits\n[CV 1/5] END learning_rate=0.5, max_depth=3, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 2/5] END learning_rate=0.5, max_depth=3, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 3/5] END learning_rate=0.5, max_depth=3, n_estimators=10;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.5, max_depth=3, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.5, max_depth=3, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 2/5] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 3/5] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.5, max_depth=3, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.5, max_depth=3, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.5, max_depth=3, n_estimators=100;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.5, max_depth=3, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 5/5] END learning_rate=0.5, max_depth=3, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.5, max_depth=3, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.5, max_depth=3, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.5, max_depth=3, n_estimators=200;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.5, max_depth=3, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 5/5] END learning_rate=0.5, max_depth=3, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.5, max_depth=5, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 2/5] END learning_rate=0.5, max_depth=5, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 3/5] END learning_rate=0.5, max_depth=5, n_estimators=10;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.5, max_depth=5, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.5, max_depth=5, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 2/5] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 3/5] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.5, max_depth=5, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.5, max_depth=5, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.5, max_depth=5, n_estimators=100;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.5, max_depth=5, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 5/5] END learning_rate=0.5, max_depth=5, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.5, max_depth=5, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.5, max_depth=5, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.5, max_depth=5, n_estimators=200;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.5, max_depth=5, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 5/5] END learning_rate=0.5, max_depth=5, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.5, max_depth=10, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 2/5] END learning_rate=0.5, max_depth=10, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 3/5] END learning_rate=0.5, max_depth=10, n_estimators=10;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.5, max_depth=10, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.5, max_depth=10, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.5, max_depth=10, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 2/5] END learning_rate=0.5, max_depth=10, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 3/5] END learning_rate=0.5, max_depth=10, n_estimators=50;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.5, max_depth=10, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.5, max_depth=10, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.5, max_depth=10, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.5, max_depth=10, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.5, max_depth=10, n_estimators=100;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.5, max_depth=10, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 5/5] END learning_rate=0.5, max_depth=10, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.5, max_depth=10, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.5, max_depth=10, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.5, max_depth=10, n_estimators=200;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.5, max_depth=10, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 5/5] END learning_rate=0.5, max_depth=10, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.5, max_depth=20, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 2/5] END learning_rate=0.5, max_depth=20, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 3/5] END learning_rate=0.5, max_depth=20, n_estimators=10;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.5, max_depth=20, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.5, max_depth=20, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.5, max_depth=20, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 2/5] END learning_rate=0.5, max_depth=20, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 3/5] END learning_rate=0.5, max_depth=20, n_estimators=50;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.5, max_depth=20, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.5, max_depth=20, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.5, max_depth=20, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.5, max_depth=20, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.5, max_depth=20, n_estimators=100;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.5, max_depth=20, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 5/5] END learning_rate=0.5, max_depth=20, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.5, max_depth=20, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.5, max_depth=20, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.5, max_depth=20, n_estimators=200;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.5, max_depth=20, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 5/5] END learning_rate=0.5, max_depth=20, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=10;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=10;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=0.958 total time=   0.2s\n[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=10;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=50;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=200;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.1, max_depth=20, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.1, max_depth=20, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.1, max_depth=20, n_estimators=10;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.1, max_depth=20, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.1, max_depth=20, n_estimators=10;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.1, max_depth=20, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 2/5] END learning_rate=0.1, max_depth=20, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 3/5] END learning_rate=0.1, max_depth=20, n_estimators=50;, score=0.833 total time=   0.0s\n[CV 4/5] END learning_rate=0.1, max_depth=20, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.1, max_depth=20, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.1, max_depth=20, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.1, max_depth=20, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.1, max_depth=20, n_estimators=100;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.1, max_depth=20, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.1, max_depth=20, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.1, max_depth=20, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.1, max_depth=20, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 3/5] END learning_rate=0.1, max_depth=20, n_estimators=200;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.1, max_depth=20, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.1, max_depth=20, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=10;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=10;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=50;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=50;, score=0.958 total time=   0.0s\n[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=0.792 total time=   0.1s\n[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=10;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=10;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=50;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=50;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=0.792 total time=   0.1s\n[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=1.000 total time=   0.2s\n[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=0.958 total time=   0.2s\n[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=10;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=10;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=50;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=50;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=100;, score=0.792 total time=   0.1s\n[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=200;, score=0.958 total time=   0.2s\n[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=200;, score=1.000 total time=   0.2s\n[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=200;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=200;, score=0.958 total time=   0.2s\n[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=200;, score=0.958 total time=   0.2s\n[CV 1/5] END learning_rate=0.01, max_depth=20, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.01, max_depth=20, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.01, max_depth=20, n_estimators=10;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.01, max_depth=20, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.01, max_depth=20, n_estimators=10;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.01, max_depth=20, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.01, max_depth=20, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.01, max_depth=20, n_estimators=50;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.01, max_depth=20, n_estimators=50;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.01, max_depth=20, n_estimators=50;, score=0.917 total time=   0.1s\n[CV 1/5] END learning_rate=0.01, max_depth=20, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 2/5] END learning_rate=0.01, max_depth=20, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 3/5] END learning_rate=0.01, max_depth=20, n_estimators=100;, score=0.792 total time=   0.1s\n[CV 4/5] END learning_rate=0.01, max_depth=20, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.01, max_depth=20, n_estimators=100;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.01, max_depth=20, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 2/5] END learning_rate=0.01, max_depth=20, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 3/5] END learning_rate=0.01, max_depth=20, n_estimators=200;, score=0.833 total time=   0.1s\n[CV 4/5] END learning_rate=0.01, max_depth=20, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 5/5] END learning_rate=0.01, max_depth=20, n_estimators=200;, score=0.958 total time=   0.1s\n[CV 1/5] END learning_rate=0.001, max_depth=3, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.001, max_depth=3, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.001, max_depth=3, n_estimators=10;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.001, max_depth=3, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.001, max_depth=3, n_estimators=10;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.001, max_depth=3, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.001, max_depth=3, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.001, max_depth=3, n_estimators=50;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.001, max_depth=3, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.001, max_depth=3, n_estimators=50;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.001, max_depth=3, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 2/5] END learning_rate=0.001, max_depth=3, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 3/5] END learning_rate=0.001, max_depth=3, n_estimators=100;, score=0.792 total time=   0.1s\n[CV 4/5] END learning_rate=0.001, max_depth=3, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.001, max_depth=3, n_estimators=100;, score=0.917 total time=   0.1s\n[CV 1/5] END learning_rate=0.001, max_depth=3, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 2/5] END learning_rate=0.001, max_depth=3, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 3/5] END learning_rate=0.001, max_depth=3, n_estimators=200;, score=0.792 total time=   0.1s\n[CV 4/5] END learning_rate=0.001, max_depth=3, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.001, max_depth=3, n_estimators=200;, score=0.917 total time=   0.2s\n[CV 1/5] END learning_rate=0.001, max_depth=5, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.001, max_depth=5, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.001, max_depth=5, n_estimators=10;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.001, max_depth=5, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.001, max_depth=5, n_estimators=10;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.001, max_depth=5, n_estimators=50;, score=1.000 total time=   0.1s\n[CV 2/5] END learning_rate=0.001, max_depth=5, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.001, max_depth=5, n_estimators=50;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.001, max_depth=5, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.001, max_depth=5, n_estimators=50;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.001, max_depth=5, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 2/5] END learning_rate=0.001, max_depth=5, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 3/5] END learning_rate=0.001, max_depth=5, n_estimators=100;, score=0.792 total time=   0.1s\n[CV 4/5] END learning_rate=0.001, max_depth=5, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.001, max_depth=5, n_estimators=100;, score=0.917 total time=   0.1s\n[CV 1/5] END learning_rate=0.001, max_depth=5, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 2/5] END learning_rate=0.001, max_depth=5, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 3/5] END learning_rate=0.001, max_depth=5, n_estimators=200;, score=0.792 total time=   0.1s\n[CV 4/5] END learning_rate=0.001, max_depth=5, n_estimators=200;, score=1.000 total time=   0.9s\n[CV 5/5] END learning_rate=0.001, max_depth=5, n_estimators=200;, score=0.917 total time=   1.6s\n[CV 1/5] END learning_rate=0.001, max_depth=10, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.001, max_depth=10, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.001, max_depth=10, n_estimators=10;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.001, max_depth=10, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.001, max_depth=10, n_estimators=10;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.001, max_depth=10, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.001, max_depth=10, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.001, max_depth=10, n_estimators=50;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.001, max_depth=10, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.001, max_depth=10, n_estimators=50;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.001, max_depth=10, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 2/5] END learning_rate=0.001, max_depth=10, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 3/5] END learning_rate=0.001, max_depth=10, n_estimators=100;, score=0.792 total time=   0.1s\n[CV 4/5] END learning_rate=0.001, max_depth=10, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.001, max_depth=10, n_estimators=100;, score=0.917 total time=   0.1s\n[CV 1/5] END learning_rate=0.001, max_depth=10, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 2/5] END learning_rate=0.001, max_depth=10, n_estimators=200;, score=1.000 total time=   0.2s\n[CV 3/5] END learning_rate=0.001, max_depth=10, n_estimators=200;, score=0.792 total time=   0.1s\n[CV 4/5] END learning_rate=0.001, max_depth=10, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.001, max_depth=10, n_estimators=200;, score=0.917 total time=   0.1s\n[CV 1/5] END learning_rate=0.001, max_depth=20, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.001, max_depth=20, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.001, max_depth=20, n_estimators=10;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.001, max_depth=20, n_estimators=10;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.001, max_depth=20, n_estimators=10;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.001, max_depth=20, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 2/5] END learning_rate=0.001, max_depth=20, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 3/5] END learning_rate=0.001, max_depth=20, n_estimators=50;, score=0.792 total time=   0.0s\n[CV 4/5] END learning_rate=0.001, max_depth=20, n_estimators=50;, score=1.000 total time=   0.0s\n[CV 5/5] END learning_rate=0.001, max_depth=20, n_estimators=50;, score=0.917 total time=   0.0s\n[CV 1/5] END learning_rate=0.001, max_depth=20, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 2/5] END learning_rate=0.001, max_depth=20, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 3/5] END learning_rate=0.001, max_depth=20, n_estimators=100;, score=0.792 total time=   0.1s\n[CV 4/5] END learning_rate=0.001, max_depth=20, n_estimators=100;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.001, max_depth=20, n_estimators=100;, score=0.917 total time=   0.1s\n[CV 1/5] END learning_rate=0.001, max_depth=20, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 2/5] END learning_rate=0.001, max_depth=20, n_estimators=200;, score=1.000 total time=   0.2s\n[CV 3/5] END learning_rate=0.001, max_depth=20, n_estimators=200;, score=0.792 total time=   0.2s\n[CV 4/5] END learning_rate=0.001, max_depth=20, n_estimators=200;, score=1.000 total time=   0.1s\n[CV 5/5] END learning_rate=0.001, max_depth=20, n_estimators=200;, score=0.917 total time=   0.2s\n","output_type":"stream"},{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"GridSearchCV(cv=5,\n             estimator=XGBClassifier(base_score=None, booster=None,\n                                     callbacks=None, colsample_bylevel=None,\n                                     colsample_bynode=None,\n                                     colsample_bytree=None, device=None,\n                                     early_stopping_rounds=None,\n                                     enable_categorical=False, eval_metric=None,\n                                     feature_types=None, gamma=None,\n                                     grow_policy=None, importance_type=None,\n                                     interaction_constraints=None,\n                                     learning_rate=None,...\n                                     max_cat_threshold=None,\n                                     max_cat_to_onehot=None,\n                                     max_delta_step=None, max_depth=None,\n                                     max_leaves=None, min_child_weight=None,\n                                     missing=nan, monotone_constraints=None,\n                                     multi_strategy=None, n_estimators=None,\n                                     n_jobs=None, num_parallel_tree=None,\n                                     random_state=None, ...),\n             param_grid={'learning_rate': [0.5, 0.1, 0.01, 0.001],\n                         'max_depth': [3, 5, 10, 20],\n                         'n_estimators': [10, 50, 100, 200]},\n             verbose=3)","text/html":"<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n             estimator=XGBClassifier(base_score=None, booster=None,\n                                     callbacks=None, colsample_bylevel=None,\n                                     colsample_bynode=None,\n                                     colsample_bytree=None, device=None,\n                                     early_stopping_rounds=None,\n                                     enable_categorical=False, eval_metric=None,\n                                     feature_types=None, gamma=None,\n                                     grow_policy=None, importance_type=None,\n                                     interaction_constraints=None,\n                                     learning_rate=None,...\n                                     max_cat_threshold=None,\n                                     max_cat_to_onehot=None,\n                                     max_delta_step=None, max_depth=None,\n                                     max_leaves=None, min_child_weight=None,\n                                     missing=nan, monotone_constraints=None,\n                                     multi_strategy=None, n_estimators=None,\n                                     n_jobs=None, num_parallel_tree=None,\n                                     random_state=None, ...),\n             param_grid={&#x27;learning_rate&#x27;: [0.5, 0.1, 0.01, 0.001],\n                         &#x27;max_depth&#x27;: [3, 5, 10, 20],\n                         &#x27;n_estimators&#x27;: [10, 50, 100, 200]},\n             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n             estimator=XGBClassifier(base_score=None, booster=None,\n                                     callbacks=None, colsample_bylevel=None,\n                                     colsample_bynode=None,\n                                     colsample_bytree=None, device=None,\n                                     early_stopping_rounds=None,\n                                     enable_categorical=False, eval_metric=None,\n                                     feature_types=None, gamma=None,\n                                     grow_policy=None, importance_type=None,\n                                     interaction_constraints=None,\n                                     learning_rate=None,...\n                                     max_cat_threshold=None,\n                                     max_cat_to_onehot=None,\n                                     max_delta_step=None, max_depth=None,\n                                     max_leaves=None, min_child_weight=None,\n                                     missing=nan, monotone_constraints=None,\n                                     multi_strategy=None, n_estimators=None,\n                                     n_jobs=None, num_parallel_tree=None,\n                                     random_state=None, ...),\n             param_grid={&#x27;learning_rate&#x27;: [0.5, 0.1, 0.01, 0.001],\n                         &#x27;max_depth&#x27;: [3, 5, 10, 20],\n                         &#x27;n_estimators&#x27;: [10, 50, 100, 200]},\n             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":70},{"cell_type":"code","source":"grid2.best_params_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:14:42.809433Z","iopub.execute_input":"2025-07-17T09:14:42.809943Z","iopub.status.idle":"2025-07-17T09:14:42.819014Z","shell.execute_reply.started":"2025-07-17T09:14:42.809913Z","shell.execute_reply":"2025-07-17T09:14:42.817410Z"}},"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}"},"metadata":{}}],"execution_count":71},{"cell_type":"code","source":"# extracting the best parameters\nlearning_rate = grid2.best_params_['learning_rate']\nmax_depth = grid2.best_params_['max_depth']\nn_estimators = grid2.best_params_['n_estimators']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:14:54.684137Z","iopub.execute_input":"2025-07-17T09:14:54.684488Z","iopub.status.idle":"2025-07-17T09:14:54.690073Z","shell.execute_reply.started":"2025-07-17T09:14:54.684465Z","shell.execute_reply":"2025-07-17T09:14:54.689053Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"xgb = XGBClassifier(learning_rate=learning_rate, max_depth=max_depth, n_estimators=n_estimators)\nxgb.fit(x_train, y_train)# training the mew model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:15:04.324161Z","iopub.execute_input":"2025-07-17T09:15:04.324616Z","iopub.status.idle":"2025-07-17T09:15:04.486022Z","shell.execute_reply.started":"2025-07-17T09:15:04.324589Z","shell.execute_reply":"2025-07-17T09:15:04.484896Z"}},"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=3, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=200, n_jobs=None,\n              num_parallel_tree=None, objective='multi:softprob', ...)","text/html":"<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=3, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=200, n_jobs=None,\n              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" checked><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=3, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=200, n_jobs=None,\n              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":73},{"cell_type":"code","source":"xgb.score(x_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:15:14.852492Z","iopub.execute_input":"2025-07-17T09:15:14.853307Z","iopub.status.idle":"2025-07-17T09:15:14.865352Z","shell.execute_reply.started":"2025-07-17T09:15:14.853276Z","shell.execute_reply":"2025-07-17T09:15:14.864460Z"}},"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"0.975"},"metadata":{}}],"execution_count":74},{"cell_type":"code","source":"xgb.score(x_test, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:15:24.859222Z","iopub.execute_input":"2025-07-17T09:15:24.860499Z","iopub.status.idle":"2025-07-17T09:15:24.871614Z","shell.execute_reply.started":"2025-07-17T09:15:24.860444Z","shell.execute_reply":"2025-07-17T09:15:24.869503Z"}},"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"1.0"},"metadata":{}}],"execution_count":75},{"cell_type":"code","source":"prediction_xgboost = xgb.predict(x_test)\nprediction_xgboost","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:15:34.210466Z","iopub.execute_input":"2025-07-17T09:15:34.210837Z","iopub.status.idle":"2025-07-17T09:15:34.222100Z","shell.execute_reply.started":"2025-07-17T09:15:34.210813Z","shell.execute_reply":"2025-07-17T09:15:34.221095Z"}},"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n       0, 2, 2, 2, 2, 2, 0, 0])"},"metadata":{}}],"execution_count":76},{"cell_type":"code","source":"xgb_score=xgb.score(x_test,y_test)\nxgb_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:15:56.320633Z","iopub.execute_input":"2025-07-17T09:15:56.320985Z","iopub.status.idle":"2025-07-17T09:15:56.335474Z","shell.execute_reply.started":"2025-07-17T09:15:56.320963Z","shell.execute_reply":"2025-07-17T09:15:56.334212Z"}},"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"1.0"},"metadata":{}}],"execution_count":77},{"cell_type":"code","source":"prediction_random_forest=clf.predict(x_test)\nprediction_random_forest","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:16:05.290735Z","iopub.execute_input":"2025-07-17T09:16:05.291114Z","iopub.status.idle":"2025-07-17T09:16:05.307422Z","shell.execute_reply.started":"2025-07-17T09:16:05.291080Z","shell.execute_reply":"2025-07-17T09:16:05.306269Z"}},"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n       0, 2, 2, 2, 2, 2, 0, 0])"},"metadata":{}}],"execution_count":78},{"cell_type":"code","source":"random_forest_score=clf.score(x_test,y_test)\nrandom_forest_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:16:14.299300Z","iopub.execute_input":"2025-07-17T09:16:14.299710Z","iopub.status.idle":"2025-07-17T09:16:14.318769Z","shell.execute_reply.started":"2025-07-17T09:16:14.299684Z","shell.execute_reply":"2025-07-17T09:16:14.317703Z"}},"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"1.0"},"metadata":{}}],"execution_count":79},{"cell_type":"code","source":"#if using for coding\ntry:\n    if len(y_test.unique()) == 1: #if there is only one label in y, then roc_auc_score returns error. We will use accuracy in that case\n        xgb_score_accuracy_score = accuracy_score(y_test, prediction_xgboost)\n        print(\"XGB accuracy_score:\"+str(xgb_score))\n    else:\n        xgb_score_roc_auc_score = roc_auc_score(y_test, prediction_xgboost) # AUC for xgb\n        print(\"XGB roc_auc_score:\"+str(xgb_score))\n       \n\n    # create best model for Random Forest\n    prediction_random_forest=clf.predict(x_test) # prediction using the Random Forest Algorithm\n\n    if len(y_test.unique()) == 1:#if there is only one label in y, then roc_auc_score returns error. We will use accuracy in that case\n        random_forest_score_accuracy_score = accuracy_score(y_test,prediction_random_forest)\n        print(\"Random Forest accuracy_score:\"+str(random_forest_score))\n    else:\n        random_forest_score_roc_auc_score = roc_auc_score(y_test, prediction_random_forest) # AUC for Random Forest\n        print(\"Random Forest roc_auc_score:\"+str(random_forest_score))\n        \n    #comparing the two models\n    if(random_forest_score <  xgb_score):\n        print(\"XGB Score:\"+str(xgb_score))\n    else:\n        print(\"Random Forest score :\"+str(random_forest_score))\nexcept Exception as e:\n    raise Exception()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:16:24.049380Z","iopub.execute_input":"2025-07-17T09:16:24.049790Z","iopub.status.idle":"2025-07-17T09:16:24.075926Z","shell.execute_reply.started":"2025-07-17T09:16:24.049763Z","shell.execute_reply":"2025-07-17T09:16:24.074054Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/4092138869.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#if there is only one label in y, then roc_auc_score returns error. We will use accuracy in that case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mxgb_score_accuracy_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_xgboost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'unique'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/4092138869.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Random Forest score :\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_forest_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mException\u001b[0m: "],"ename":"Exception","evalue":"","output_type":"error"}],"execution_count":80},{"cell_type":"code","source":"xgb_score_accuracy_score = accuracy_score(y_test, prediction_xgboost)\nprint(xgb_score_accuracy_score)\nprint(\"XGB roc_auc_score:\"+str(xgb_score))\nprint(\"Random Forest accuracy_score:\"+str(random_forest_score))\nprint(\"Random Forest roc_auc_score:\"+str(random_forest_score))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:16:39.026385Z","iopub.execute_input":"2025-07-17T09:16:39.026710Z","iopub.status.idle":"2025-07-17T09:16:39.034342Z","shell.execute_reply.started":"2025-07-17T09:16:39.026689Z","shell.execute_reply":"2025-07-17T09:16:39.033277Z"}},"outputs":[{"name":"stdout","text":"1.0\nXGB roc_auc_score:1.0\nRandom Forest accuracy_score:1.0\nRandom Forest roc_auc_score:1.0\n","output_type":"stream"}],"execution_count":81},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}